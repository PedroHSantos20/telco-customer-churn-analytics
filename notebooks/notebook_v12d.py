# -*- coding: utf-8 -*-
"""Notebook_v12d.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wooCtz7taQV6XwIEybFu0Sz_pR39tlF

#1.Telco Customer Churn Analysis

Subject: Predicting Customer Churn in Telecommunications Sector

Our project will follow a 7-step methodology that is closely aligned with well-known frameworks used in data science projects, such as CRISP-DM, Microsoft TDSP, and KDnuggets Modern Data Science Process. The 7-steps are as follows:

1. Environment Setup and Configuration
2. Data Integration and Cleaning
3. Exploratory Data Analysis (EDA) & Business Questions
4. Feature Engineering
5. Predictive Modelling
6. Model Evaluation
7. Best Model Details
8. Hugging Face Integration
9. Business Recommendations

## 1.1-Environment Setup and Configuration
"""

# For Google Colab: Mount Google Drive

from google.colab import drive
from pathlib import Path
import os

drive.mount('/content/drive')

# =====================================================
# Define paths
# =====================================================

project_path = '/content/drive/MyDrive/Colab Notebooks/Bootcamp/Telco_Churn_Project/'

data_path = project_path + '01_Data/'
notebook_path = project_path + '02_Notebooks/'
output_path = project_path + '03_Outputs/'
artifacts_path = project_path + '04_Artifacts/'

# =====================================================
# Create folders if they do not exist
# =====================================================

folders_to_create = [
    data_path,
    notebook_path,
    output_path,
    artifacts_path
]

for folder in folders_to_create:
    if not os.path.exists(folder):
        os.makedirs(folder)
        print(f"Created folder: {folder}")
    else:
        print(f"Folder already exists: {folder}")

# =====================================================
# Import Python libraries
# =====================================================

!pip install polars[excel]

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

print("Setup has been completed")

"""##1.2-Upload Data to Dataframes

"""

demographics_df = pl.read_excel(f"{data_path}Telco_customer_churn_demographics.xlsx")
status_df      = pl.read_excel(f"{data_path}Telco_customer_churn_status.xlsx")
population_df  = pl.read_excel(f"{data_path}Telco_customer_churn_population.xlsx")
location_df    = pl.read_excel(f"{data_path}Telco_customer_churn_location.xlsx")
services_df    = pl.read_excel(f"{data_path}Telco_customer_churn_services.xlsx")

print(f"  - Demographics: {demographics_df.shape}")
print(f"  - Status: {status_df.shape}")
print(f"  - Population: {population_df.shape}")
print(f"  - Location: {location_df.shape}")
print(f"  - Services: {services_df.shape}")

print(f"\nAll external files were sucessfully imported.")

"""#**2.Data Integration and Cleaning**

##2.1-Data Knowledge

  Display schema and head rows of each dataframe
"""

print("demographics_df.schema & head rows")
display(demographics_df.head(5))

print("status_df.schema & head rows")
display(status_df.head(5))

print("population_df.schema & head rows")
display(population_df.head(5))

print("location_df.schema & head rows")
display(location_df.head(5))

print("services_df.schema & head rows")
display(services_df.head(5))

"""##2.2-Data Consolidation

Include all data in one dataframe

###2.2.1-Include all data in one dataframe
"""

print("Merging datasets...\n")

df = demographics_df.clone()

# Merge location, services, status and population data
df = df.join(location_df, on="Customer ID", how="left", suffix="_loc")
df = df.join(services_df, on="Customer ID", how="left", suffix="_svc")
df = df.join(status_df, on="Customer ID", how="left", suffix="_sts")
df = df.join(
    population_df.select(["Zip Code", "Population"]),
    on="Zip Code",
    how="left"
)

print(f"\nMerged dataset name: df, shape {df.shape}")

"""###2.2.2-Remove duplicated columns"""

print("\nRemoving duplicate columns...")

# Identify columns with suffixes
cols_to_drop = [
    col for col in df.columns
    if col.endswith("_loc") or col.endswith("_svc") or col.endswith("_sts")
]

# Drop them
df = df.drop(cols_to_drop)

print(f"Dropped {len(cols_to_drop)} duplicate columns")
print(f"Final dataset name: df, shape: {df.shape}\n")

"""###2.2.3-Check Missing Values"""

print("Checking for missing values...\n")

# Count missing values per column
missing_summary = (
    pl.DataFrame({
        "Column": df.columns,
        "Missing_Count": [df[col].null_count() for col in df.columns],
    })
    .with_columns([
        (pl.col("Missing_Count") / len(df) * 100)
        .round(2)
        .alias("Missing_Percentage")
    ])
    .filter(pl.col("Missing_Count") > 0)
    .sort("Missing_Count", descending=True)
)

if missing_summary.height > 0:
    print("\nColumns with missing values:")
    print(missing_summary)
else:
    print("\nNo missing values found")

"""**Attention to this:** The Churn Category and Churn Reason fields are mostly empty. This could be a limitation because these features could be important to explain the prediction model.

###2.2.4-Save integrated dataset & Create data dictionary
"""

print("Saving integrated dataset...\n")

# Save integrated dataset
df.write_csv(f"{output_path}telco_churn_integrated.csv")
print(f"Integrated dataset saved to: {output_path}telco_churn_integrated.csv")

print("Creating data dictionary...\n")

data_dict = pl.DataFrame({
    "Variable": df.columns,
    "Type": [str(dtype) for dtype in df.dtypes],
    "Non_Null_Count": [df[col].len() - df[col].null_count() for col in df.columns],
    "Unique_Values": [df[col].n_unique() for col in df.columns],
    "Sample_Values": [
        str(df[col].drop_nulls().unique().limit(3).to_list()) for col in df.columns
    ],
})

data_dict.write_csv(f"{output_path}data_dictionary.csv")
print(f"Data dictionary saved to: {output_path}data_dictionary.csv")

"""#**3.Exploratory Data Analysis**

##3.1-Target variable distribution
"""

import polars as pl
import matplotlib.pyplot as plt

#Compute churn counts and percentages
churn_stats = (
    df.group_by("Churn Label")
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum() * 100)
          .round(2)
          .alias("Percentage")
      )
      .sort("Churn Label")
)

labels = churn_stats.get_column("Churn Label").to_list()
counts = churn_stats.get_column("Count").to_list()
percentages = churn_stats.get_column("Percentage").to_list()
total = sum(counts)

color_map = {
    "No": "#2ecc71",
    "No Churn": "#2ecc71",
    "Stayed": "#2ecc71",
    "Yes": "#e74c3c",
    "Churn": "#e74c3c",
    "Churned": "#e74c3c"
}
colors = [color_map.get(lbl, "#3498db") for lbl in labels]

#Create Horizontal Bar Chart
fig_bar, ax_bar = plt.subplots(figsize=(9, 5), dpi=150)

y_pos = range(len(labels))
ax_bar.barh(y_pos, counts, color=colors, alpha=0.9)

#Add labels: "count (xx.x%)"
for i, (c, p) in enumerate(zip(counts, percentages)):
    ax_bar.text(
        c + max(counts)*0.01,  #offset to the right
        i,
        f"{c} ({p:.1f}%)",
        va="center",
        fontsize=11,
        fontweight="bold"
    )

ax_bar.set_yticks(y_pos)
ax_bar.set_yticklabels(labels, fontsize=10)
ax_bar.set_xlabel("Number of Customers", fontsize=10)
ax_bar.set_title("Customer Churn Distribution", fontsize=12, fontweight="bold")
ax_bar.grid(axis="x", linestyle="--", alpha=0.3)

plt.tight_layout()
bar_path = f"{output_path}churn_distribution_bar.png"
fig_bar.savefig(bar_path, bbox_inches="tight")
plt.show()
plt.close(fig_bar)

print(f"\nBar chart saved: {bar_path}")

"""In churn datasets, it's very common to see something like Non-Churn (70-90%), Churn (10-30%), this is the classical annual customer behaviour. In our case we have a dataset with Churn equal to 26,5% so, yes our dataset is inbalanced but this should not be an issue if correctly adressed in the predict models that we will use.

**Gradient boosting (XGBoost):** Very robust to imbalance because:

*   Optimize log-loss, not accuracy.
*   Implicitly weight misclassifications more on the minority class.
*   Split trees based on information gain, which is sensitive to minority classes.   

In practice XGBoost behaves well up to 1:20 imbalance without any intervention. Our dataset is very close (around 1:3 or 1:4 imbalance).

**Random Forest and Logistic Regression:** We can use hiper_parameter "'class_weight = 'balanced'" and "Threshold tuning". Because the imbalance level in our dataset is not extreme, this should be enough to use those models  with confidence on the results. To optimize the classification threshold we will not use the default value of 0.5, instead after some simulations we decided to use a threshold between 0.30 and 0.45.

In this kind of problems (Churn prediction) the real issue is not imbalance, the real issues for the companies are it's thresholds and the business cost. In fact, in churn, the cost of predictions is asymmetric and, due to that, the focus should stay on:

**False Negative (churner predicted as non-churn):** Which implies loss of customer lifetime value.

**False Positive (non churned predicted as churner):** Spend money and resources on unnecessary retention campaign's.

##3.2-Descritive Statistics
"""

print("\nDescriptive Statistics for Numerical Variables")

# Select numeric columns
numerical_cols = [
    col for col, dtype in df.schema.items()
    if dtype in (pl.Int8, pl.Int16, pl.Int32, pl.Int64,
                 pl.UInt8, pl.UInt16, pl.UInt32, pl.UInt64,
                 pl.Float32, pl.Float64)
]

desc_stats = df.select(numerical_cols).describe()
display(desc_stats)

# Save to CSV
desc_stats.write_csv(f"{output_path}descriptive_statistics.csv")

print(f"\nDescriptive Statistics saved to: {output_path}descriptive_statistics.csv")

"""##3.3-Churn by demographic's

Variables:

*  Churn Rate By Gender
*  Churn Rate By Group Age
*  Churn Rate By Senior Citizen
*  Churn Rate By Marital Status

"""

def ensure_no_yes_order(df, id_col):
    desired_order = [id_col, "No", "Yes"]
    return df.select([c for c in desired_order if c in df.columns])

#By Gender
gender_churn = (
    df.group_by(["Gender", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Gender") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(
          values="Percentage",
          index="Gender",
          columns="Churn Label"
      )
      .fill_null(0)
      .sort("Gender")
)

print("\nChurn Rate by Gender (%):")
gender_churn = ensure_no_yes_order(gender_churn, "Gender")
print(gender_churn)

#By Group Age
df = df.with_columns(
    pl.when(pl.col("Age") <= 30).then(pl.lit("<30"))
     .when(pl.col("Age") <= 50).then(pl.lit("30-50"))
     .when(pl.col("Age") <= 65).then(pl.lit("50-65"))
     .otherwise(pl.lit("65+"))
     .alias("Age_Group")
)

age_churn = (
    df.group_by(["Age_Group", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Age_Group") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(
          values="Percentage",
          index="Age_Group",
          columns="Churn Label"
      )
      .fill_null(0)
      .sort("Age_Group")
)

print("\nChurn Rate by Group Age (%):")
age_churn = ensure_no_yes_order(age_churn, "Age_Group")
print(age_churn)

#Senior Citizen
senior_churn = (
    df.group_by(["Senior Citizen", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Senior Citizen") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(
          values="Percentage",
          index="Senior Citizen",
          columns="Churn Label"
      )
      .fill_null(0)
      .sort("Senior Citizen")
)

print("\nChurn Rate by Senior Citizen (%):")
senior_churn = ensure_no_yes_order(senior_churn, "Senior Citizen")
print(senior_churn)

#By Marital Status
married_churn = (
    df.group_by(["Married", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Married") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(
          values="Percentage",
          index="Married",
          columns="Churn Label"
      )
      .fill_null(0)
      .sort("Married")
)

print("\nChurn Rate by Marital Status (%):")
married_churn = ensure_no_yes_order(married_churn, "Married")
print(married_churn)

"""##3.4-Churn by Service Variables

*   Churn Rate By Contract Type
*   Churn Rate By Internet Type
*   Churn Rate By Payment Method


"""

# Contract Type
contract_churn = (
    df.group_by(["Contract", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Contract") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(values="Percentage", index="Contract", columns="Churn Label")
      .fill_null(0)
      .sort("Contract")
)

print("\nChurn Rate by Contract Type (%):")
contract_churn  = ensure_no_yes_order(contract_churn,  "Contract")
print(contract_churn)

# Internet Type
internet_churn = (
    df.group_by(["Internet Type", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Internet Type") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(values="Percentage", index="Internet Type", columns="Churn Label")
      .fill_null(0)
      .sort("Internet Type")
)

print("\nChurn Rate by Internet Type (%):")
internet_churn  = ensure_no_yes_order(internet_churn,  "Internet Type")
print(internet_churn)

# Payment Method
payment_churn = (
    df.group_by(["Payment Method", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Payment Method") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(values="Percentage", index="Payment Method", columns="Churn Label")
      .fill_null(0)
      .sort("Payment Method")
)

print("\nChurn Rate by Payment Method (%):")
payment_churn   = ensure_no_yes_order(payment_churn,   "Payment Method")
print(payment_churn)

"""##3.5-Churn by Tenure

(Customer longevity: The number of months a customer stayed subscribed, i.e costumer longevity in months).
"""

# Create tenure group
df = df.with_columns(
    pl.when(pl.col("Tenure in Months") <= 12).then(pl.lit("0-12m"))
     .when(pl.col("Tenure in Months") <= 24).then(pl.lit("12-24m"))
     .when(pl.col("Tenure in Months") <= 48).then(pl.lit("24-48m"))
     .otherwise(pl.lit("48m+"))
     .alias("Tenure_Group")
)

# Crosstab equivalent
tenure_churn = (
    df.group_by(["Tenure_Group", "Churn Label"])
      .agg(pl.len().alias("Count"))
      .with_columns(
          (pl.col("Count") / pl.col("Count").sum().over("Tenure_Group") * 100)
          .round(2)
          .alias("Percentage")
      )
      .pivot(
          values="Percentage",
          index="Tenure_Group",
          columns="Churn Label"
      )
      .fill_null(0)
      .sort("Tenure_Group")
)

print("\nChurn Rate by Tenure Group (%):")
tenure_churn = ensure_no_yes_order(tenure_churn, "Tenure_Group")
print(tenure_churn)

"""##3.6-Financial Metrics

*  Monthly Charge
*  Total Revenue
*  CLTV (Customer Life Time Value)
*  Total Charges

"""

financial_cols = ["Monthly Charge", "Total Revenue", "CLTV", "Total Charges"]

#Compute averages by churn label
financial_by_churn = (
    df.group_by("Churn Label")
      .agg([pl.col(c).mean().alias(c) for c in financial_cols])
      .sort("Churn Label")
)

#Format values as currency (€)
formatted = financial_by_churn.with_columns([
    pl.col(c).map_elements(lambda v: f"€{v:,.2f}").alias(c)
    for c in financial_cols
])

print("\nAverage Financial Metrics by Churn:")
print(formatted)

"""##3.7-Churn by Location (City)

Not relevant because only one country (EUA), and one state (California) is present on the dataset. We maintain geographic analysis using city but, even so, small cities with a small number of customers apears in the top ten. It will be preferable to organize cities by counties/districts (we should return where at the end if we have time).
"""

geo_churn = (
    df.group_by("City")
      .agg([
          pl.count("Customer ID").alias("Total_Customers"),
          (pl.col("Churn Label") == "Yes").sum().alias("Churned_Customers")
      ])
      .with_columns(
          ((pl.col("Churned_Customers") / pl.col("Total_Customers")) * 100)
          .round(2)
          .alias("Churn_Rate")
      )
      .sort("Churn_Rate", descending=True)
)

#Save to CSV
geo_churn.write_csv(f"{output_path}churn_by_city.csv")
print(f"Geographic churn analysis saved: {output_path}churn_by_city.csv")

#Show top 10 Cities
print("\nTop 10 Cities by Churn Rate:")
print(geo_churn.head(10))

"""##3.8-Correlation Analysis (Pearson's vs Spearman)


We discuss the use of Pearson's or Spearman Correlation methods.

Pearsons works well when: Variables are continuous; Relationships are linear; There are no extreme outliers, and; Data is approximately normal distribution.

Spearman works better if its necessary: To handle nonlinear but monotonic (the direction of change is consistent, even if the rate of change is not) patterns; Outliers; Work with ordinal, categorical encoded, or skewed variables, or; Capture effects like "high-Medium-Low" that are not linearly spaced.

As could be confirmed if both correlations are computed, Spearman gives stronger signal in churn datasets because:

1.   **Many relationships are monotonic, not linear:**

    *   Tenure ↓ -> Churn ↑
    *   MonthlyCharges ↑ -> Churn ↑
    *   Number of add-on services ↑ -> Churn ↓
    *   Payment method (e.g., electronic check) -> higher churn but not linearly spaced  

These patterns are directional, but not linear and **Spearman captures directions but Pearson's** do not.

2.   **Many variables in the dataset are ordinal disguised as numeric:**

    *   Tenure in Months
    *   Age
    *   Number of tickets
    *   Number of services
    *   Billing methods
    *   Contract type (encoded as 0/1/2)

**Pearson** treats the spacing as equal intervals, which is false. **Spearman** ignores the spacing and only cares about the order.

3.   **Churn is a binary variable:** Correlations with binary variables often violate Pearson assumptions. Spearman handles binary targets better because ranks are more meaningful.

4.   **Strong skewness and long tails:** Our dataset has variables like:

    *   MonthlyCharges
    *   TotalCharges
    *   Revenue
    *   Tenure

The distribution of these variables are not symmetric and contain outliers. Both characteristics that are bad for Pearson.

For educational purposes, we kept the Pearson correlation code in the notebook, commented out. Running it allows an immediate comparison and confirms that the values are broadly aligned with those obtained using Spearman. However, as expected, Spearman provides a more robust and meaningful measure of association in this dataset, as it better captures the monotonic patterns typical of churn-related variables.

# Select numerical columns for correlation
corr_cols = [
    "Age", "Tenure in Months", "Monthly Charge", "Total Revenue", "CLTV",
    "Satisfaction Score", "Churn Score", "Number of Referrals",
    "Avg Monthly GB Download", "Population"
]

# Compute Pearson's correlation matrix
corr_matrix = df.select(corr_cols).corr()

# Display correlation matrix
print("\nPearson's Correlation Matrix:")
print(corr_matrix)

# Save to CSV
corr_file = f"{output_path}Pearsons_correlation_matrix.csv"
corr_matrix.write_csv(corr_file)
print(f"\nPearson's Correlation matrix saved: {corr_file}")

# corr_matrix is a Polars DataFrame from: corr_matrix = df.select(corr_cols).corr()

# 1) Extract variable names from Polars'
if "column" in corr_matrix.columns:
    names = corr_matrix.get_column("column").to_list()
    vals_pl = corr_matrix.drop("column")
else:
    names = corr_cols
    vals_pl = corr_matrix

# 2) Convert values to pandas and set both axes labels
corr_pd = vals_pl.to_pandas()
corr_pd.index = names
corr_pd.columns = names

# 3) Display the heat map
plt.figure(figsize=(12, 10))
sns.heatmap(
    corr_pd.astype(float),
    annot=True,
    fmt=".2f",
    cmap="coolwarm",
    center=0,
    square=True,
    linewidths=1,
    cbar_kws={"shrink": 0.8},
)
plt.title("Pearson's Correlation Matrix of Numerical Variables", fontsize=16, fontweight="bold")
plt.xticks(rotation=45, ha="right")
plt.yticks(rotation=0)
plt.tight_layout()

# Show and save
plt.show()
heatmap_path = f"{output_path}Pearson's correlation_heatmap.png"
plt.savefig(heatmap_path, dpi=300, bbox_inches="tight")
print(f"Pearson's Correlation heatmap displayed and saved: {heatmap_path}")
"""

#Select numerical columns for correlation
corr_cols = [
    "Age", "Tenure in Months", "Monthly Charge", "Total Revenue", "CLTV",
    "Satisfaction Score", "Churn Score", "Number of Referrals",
    "Avg Monthly GB Download", "Population"
]

#Convert to pandas and compute Spearman correlation (from df dataset)
df_pd = df.select(corr_cols).to_pandas()
corr_matrix = df_pd.corr(method="spearman").round(3)

# --- Create heatmap ---
plt.figure(figsize=(10, 8), dpi=150)
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap="RdBu_r",
    center=0,
    linewidths=0.5,
    cbar_kws={"label": "Spearman Correlation"}
)

plt.title("Spearman Correlation Heatmap", fontsize=8, pad=8)
plt.xticks(rotation=45, ha="right")
plt.yticks(rotation=0)
plt.tight_layout()

#Show heatmap on screen
plt.show()

#Save as png file
png_path = f"{output_path}Spearman_correlation_heatmap.png"
plt.savefig(png_path, bbox_inches="tight")
print(f"Spearman heatmap saved: {png_path}")

"""##3.9-Additional Business Questions

###3.9.1-Temporal and Lifecycle Analysis (Q4)

**Q4. What is the critical period, in months, when customers are most likely to churn?**

**Justification:** Identifying periods of risk enables proactive retention measures to be taken at specific stages of the customer lifecycle.

**Analysis:** Group customers by tenure ranges and calculate churn rates to identify the most vulnerable periods in customer lifecycle.
"""

def q4_critical_tenure_analysis(df):

    print("\033[1mQ4. What is the critical period, in months, when customers are most likely to churn?\033[0m")


    # Create tenure groups
    df_analysis = df.with_columns([
        pl.when(pl.col('Tenure in Months') < 6).then(pl.lit('0-6 months'))
        .when(pl.col('Tenure in Months') < 12).then(pl.lit('6-12 months'))
        .when(pl.col('Tenure in Months') < 24).then(pl.lit('12-24 months'))
        .when(pl.col('Tenure in Months') < 36).then(pl.lit('24-36 months'))
        .when(pl.col('Tenure in Months') < 48).then(pl.lit('36-48 months'))
        .otherwise(pl.lit('48+ months'))
        .alias('Tenure_Group')
    ])

    # Base metrics (numerical)
    tenure_churn = (
        df_analysis.group_by('Tenure_Group')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count()
                .alias('Churned_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count()
                / pl.count('Customer ID') * 100
            ).alias('Churn_Rate'),
            pl.col('Tenure in Months').mean().alias('Avg_Tenure'),
            pl.col('Total Revenue').sum().alias('Total_Revenue')
        ])
        .sort('Avg_Tenure')
    )

    formatted_table = tenure_churn.with_columns([
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%").alias("Churn_Rate"),
        pl.col("Avg_Tenure").map_elements(lambda v: f"{v:.2f}").alias("Avg_Tenure"),
        pl.col("Total_Revenue").map_elements(lambda v: f"€{v:,.2f}").alias("Total_Revenue")
    ])

    print("\nChurn Rate by Tenure Group:")
    print(formatted_table)

    tenure_data = tenure_churn.to_pandas()

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # Churn rate
    ax1.bar(tenure_data['Tenure_Group'], tenure_data['Churn_Rate'], color='#E63946')
    ax1.set_xlabel('Tenure Group', fontweight='bold')
    ax1.set_ylabel('Churn Rate (%)', fontweight='bold')
    ax1.set_title('Churn Rate (%) by Tenure Period', fontsize=12, fontweight='bold')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(axis='y', alpha=0.3)

    # Customer distribution
    ax2.bar(tenure_data['Tenure_Group'], tenure_data['Total_Customers'], color='#457B9D')
    ax2.set_xlabel('Tenure Group', fontweight='bold')
    ax2.set_ylabel('Number of Customers', fontweight='bold')
    ax2.set_title('Number of Customers (Distribution) by Tenure Period', fontsize=12, fontweight='bold')
    ax2.tick_params(axis='x', rotation=45)
    ax2.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path + '/q4_tenure_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    contingency_table = (
        df_analysis.group_by(['Tenure_Group', 'Customer Status'])
        .agg(pl.count('Customer ID').alias('Count'))
        .pivot(index='Tenure_Group', columns='Customer Status', values='Count')
        .fill_null(0)
    )

    print("\nKey Insights:")
    critical_period = tenure_churn.filter(pl.col('Churn_Rate') == pl.col('Churn_Rate').max())
    print(f"Most critical period: {critical_period['Tenure_Group'][0]} with {critical_period['Churn_Rate'][0]:.2f}% churn rate")
    print(f"Safest period: {tenure_churn.filter(pl.col('Churn_Rate') == pl.col('Churn_Rate').min())['Tenure_Group'][0]}")

    return tenure_churn

# call Q4
tenure_results = q4_critical_tenure_analysis(df)

"""###3.9.2-Financial Dimension and Customer Value (Q6, Q7, Q8)

**Q6. What is the relationship between customer lifetime value (CLV) and the probability of churn?**  

**Justification:** Prioritising retention efforts for high-value customers can maximise campaign ROI.

**Analysis:** Segmentation by CLTV; churn rate analysis by segment; calculation of the financial impact of churn.
"""

def q6_cltv_churn_analysis(df):

    print("\033[1mQ6. What is the relationship between customer lifetime value (CLV) and the probability of churn?\033[0m")

    # Create CLTV groups
    df_analysis = df.with_columns([
        pl.col('CLTV')
        .qcut(4, labels=['Low', 'Medium', 'High', 'Very High'])
        .alias('CLTV_Segment')
    ])

    # Numerical metrics
    cltv_churn = (
        df_analysis
        .group_by('CLTV_Segment')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            pl.col('Customer Status')
              .filter(pl.col('Customer Status') == 'Churned')
              .count()
              .alias('Churned_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count()
                / pl.count('Customer ID') * 100
            ).alias('Churn_Rate'),
            pl.col('CLTV').mean().alias('Avg_CLTV'),
            pl.col('Total Revenue').sum().alias('Total_Revenue')
        ])
        .sort('Avg_CLTV')
    )

    formatted = cltv_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churned_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_CLTV").map_elements(lambda v: f"€{v:,.2f}"),
        pl.col("Total_Revenue").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nChurn Rate by CLTV Segment:")
    print(formatted)

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    cltv_data = cltv_churn.to_pandas()

    # Plot 1: Churn rate by CLTV segment
    axes[0].bar(
        cltv_data['CLTV_Segment'],
        cltv_data['Churn_Rate'],
        color=['#E63946', '#F4A261', '#457B9D', '#2A9D8F']
    )
    axes[0].set_xlabel('CLTV Segment', fontweight='bold')
    axes[0].set_ylabel('Churn Rate (%)', fontweight='bold')
    axes[0].set_title('Churn Rate by Customer Lifetime Value Segment',
                      fontsize=14, fontweight='bold')
    axes[0].grid(axis='y', alpha=0.3)

    # Plot 2: Revenue at risk
    revenue_at_risk = cltv_data['Total_Revenue'] * cltv_data['Churn_Rate'] / 100

    axes[1].bar(
        cltv_data['CLTV_Segment'],
        revenue_at_risk / 1_000_000,
        color=['#E63946', '#F4A261', '#457B9D', '#2A9D8F']
    )
    axes[1].set_xlabel('CLTV Segment', fontweight='bold')
    axes[1].set_ylabel('Revenue at Risk (€ millions)', fontweight='bold')
    axes[1].set_title('Revenue at Risk by CLTV Segment',
                      fontsize=14, fontweight='bold')
    axes[1].grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path + '/q6_cltv_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    correlation = (
        df.with_columns(
            pl.col('Customer Status')
            .replace({'Churned': 1, 'Stayed': 0, 'Joined': 0})
            .cast(pl.Int8)
            .alias('Churn_Flag')
        )
        .select(
            pl.corr('CLTV', 'Churn_Flag').alias('CLTV_Churn_Correlation')
        )
    )

    print("\nKey Insights:")
    print(f"CLTV-Churn Correlation: {correlation['CLTV_Churn_Correlation'][0]:.4f}")

    high_value_churn = cltv_churn.filter(pl.col('CLTV_Segment') == 'Very High')
    print(f"High-value customer churn rate: {high_value_churn['Churn_Rate'][0]:.2f}%")

    print(
        "Total revenue at risk: "
        f"€{(revenue_at_risk.sum() / 1_000_000):.2f}M"
    )

    return cltv_churn

# Call Q6 function
cltv_results = q6_cltv_churn_analysis(df)

"""**Q7. Are customers who have received a total refund or extra charges more likely to churn?**

**Justification:** Billing issues and unexpected charges are often cited as reasons for dissatisfaction.

**Analysis:** Correlation between financial variables and churn; analysis of churn reasons related to costs.

"""

def q7_refunds_charges_analysis(df):

    print("\033[1mQ7. Are customers who have received refund's or extra charges more likely to churn?\033[0m")

    import numpy as np
    from scipy import stats

    # --- 1. Analysis by Customer Status ---
    refund_analysis = (
        df.group_by('Customer Status')
          .agg([
              pl.col('Total Refunds')
                .filter(pl.col('Total Refunds') > 0)
                .count()
                .alias('Customers_With_Refunds'),
              pl.col('Total Refunds').mean().alias('Avg_Refund'),
              pl.col('Total Extra Data Charges').mean().alias('Avg_Extra_Charges'),
              pl.col('Total Long Distance Charges').mean().alias('Avg_LD_Charges')
          ])
    )

    refund_analysis_fmt = refund_analysis.with_columns([
        pl.col("Customers_With_Refunds").map_elements(lambda v: f"{v:,d}"),
        pl.col("Avg_Refund").map_elements(lambda v: f"€{v:,.2f}"),
        pl.col("Avg_Extra_Charges").map_elements(lambda v: f"€{v:,.2f}"),
        pl.col("Avg_LD_Charges").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nRefunds and Charges by Customer Status:")
    print(refund_analysis_fmt)

    # --- 2. Refund categories and churn ---
    df_analysis = df.with_columns([
        pl.when(pl.col('Total Refunds') == 0).then(pl.lit('No Refunds'))
         .when(pl.col('Total Refunds') < 50).then(pl.lit('Low Refunds'))
         .when(pl.col('Total Refunds') < 100).then(pl.lit('Medium Refunds'))
         .otherwise(pl.lit('High Refunds'))
         .alias('Refund_Category')
    ])

    refund_churn = (
        df_analysis
        .group_by('Refund_Category')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count()
                / pl.count('Customer ID') * 100
            ).alias('Churn_Rate')
        ])
        .sort('Churn_Rate', descending=True)
    )

    refund_churn_fmt = refund_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%")
    ])

    print("\nChurn Rate by Refund Category:")
    print(refund_churn_fmt)

    # --- 3. Visualisation ---
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    refund_data = refund_churn.to_pandas()
    refund_status_data = refund_analysis.to_pandas()

    # Plot 1: Churn rate by refund category
    axes[0, 0].bar(refund_data['Refund_Category'], refund_data['Churn_Rate'], color='#E63946')
    axes[0, 0].set_xlabel('Refund Category', fontweight='bold')
    axes[0, 0].set_ylabel('Churn Rate (%)', fontweight='bold')
    axes[0, 0].set_title('Churn Rate by Refund Category', fontsize=12, fontweight='bold')
    axes[0, 0].tick_params(axis='x', rotation=45)
    axes[0, 0].grid(axis='y', alpha=0.3)

    # Plot 2: Average refunds by customer status
    axes[0, 1].bar(refund_status_data['Customer Status'], refund_status_data['Avg_Refund'], color='#457B9D')
    axes[0, 1].set_xlabel('Customer Status', fontweight='bold')
    axes[0, 1].set_ylabel('Average Refund (€)', fontweight='bold')
    axes[0, 1].set_title('Average Refunds by Customer Status', fontsize=12, fontweight='bold')
    axes[0, 1].grid(axis='y', alpha=0.3)

    # Plot 3: Extra data charges impact
    axes[1, 0].bar(refund_status_data['Customer Status'], refund_status_data['Avg_Extra_Charges'], color='#F4A261')
    axes[1, 0].set_xlabel('Customer Status', fontweight='bold')
    axes[1, 0].set_ylabel('Avg Extra Data Charges (€)', fontweight='bold')
    axes[1, 0].set_title('Extra Data Charges by Customer Status', fontsize=12, fontweight='bold')
    axes[1, 0].grid(axis='y', alpha=0.3)

    # Plot 4: Long distance charges impact
    axes[1, 1].bar(refund_status_data['Customer Status'], refund_status_data['Avg_LD_Charges'], color='#2A9D8F')
    axes[1, 1].set_xlabel('Customer Status', fontweight='bold')
    axes[1, 1].set_ylabel('Avg LD Charges (€)', fontweight='bold')
    axes[1, 1].set_title('Long Distance Charges by Customer Status', fontsize=12, fontweight='bold')
    axes[1, 1].grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig(output_path + '/q7_refunds_charges_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

    #4. Statistical Test
    churned_refunds = df.filter(pl.col('Customer Status') == 'Churned')['Total Refunds'].to_numpy()
    stayed_refunds = df.filter(pl.col('Customer Status') == 'Stayed')['Total Refunds'].to_numpy()

    if len(churned_refunds) > 2 and len(stayed_refunds) > 2:
        t_stat, p_value = stats.ttest_ind(
            churned_refunds,
            stayed_refunds,
            equal_var=False,
            nan_policy='omit'
        )

        # Cohen’s d
        mean_churn = np.nanmean(churned_refunds)
        mean_stayed = np.nanmean(stayed_refunds)
        std_churn = np.nanstd(churned_refunds, ddof=1)
        std_stayed = np.nanstd(stayed_refunds, ddof=1)
        pooled_sd = np.sqrt(((std_churn ** 2) + (std_stayed ** 2)) / 2)
        cohen_d = (mean_churn - mean_stayed) / pooled_sd if pooled_sd > 0 else np.nan

        print("\nKey Insights:")
        print(f"T-test p-value for refunds (Churned vs Stayed): {p_value:.4f}")
        print(f"Cohen's d (effect size): {cohen_d:.3f}")

        stats_summary = {
            "t_stat": float(t_stat),
            "p_value": float(p_value),
            "cohen_d": float(cohen_d)
        }
    else:
        print("\nKey Insights:")
        print("Not enough observations to run a reliable t-test.")
        stats_summary = None

    return refund_analysis_fmt, refund_churn_fmt, stats_summary

# call Q7 function
refunds_results = q7_refunds_charges_analysis(df)

"""**Q8.** How does the payment method impact the churn rate?  

**Justification:** Different payment methods may indicate different levels of commitment and friction in the process.  

**Analysis:** Compare churn rates across different payment methods to identify which payment types are associated with higher retention.

"""

def q8_payment_method_analysis(df):

    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.ticker as mtick

    print("\033[1mQ8. How does the payment method impact the churn rate?\033[0m")

    # Aggregate churn metrics by payment method
    payment_churn = (
        df.group_by('Payment Method')
          .agg([
              pl.count('Customer ID').alias('Total_Customers'),
              pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count()
                .alias('Churned_Customers'),
              (
                  pl.col('Customer Status')
                  .filter(pl.col('Customer Status') == 'Churned')
                  .count()
                  / pl.count('Customer ID') * 100
              ).alias('Churn_Rate'),
              pl.col('Monthly Charge').mean().alias('Avg_Monthly_Charge')
          ])
          .sort('Churn_Rate', descending=True)
    )

    payment_churn_fmt = payment_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churned_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_Monthly_Charge").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nChurn Rate by Payment Method:")
    print(payment_churn_fmt)

    # Prepare data for visualisation (numeric)
    payment_data = payment_churn.to_pandas()
    payment_data['Churn_pct'] = payment_data['Churn_Rate'] / 100.0
    payment_data['Stayed_pct'] = 1.0 - payment_data['Churn_pct']

    fig, ax = plt.subplots(figsize=(12, 6))

    y_pos = np.arange(len(payment_data))

    # Stayed segment
    ax.barh(
        y_pos,
        payment_data['Stayed_pct'],
        color='#2A9D8F',
        label='Stayed',
        height=0.45
    )

    # Churned segment
    ax.barh(
        y_pos,
        payment_data['Churn_pct'],
        left=payment_data['Stayed_pct'],
        color='#E63946',
        label='Churned',
        height=0.45
    )

    # Y-axis labels
    ax.set_yticks(y_pos)
    ax.set_yticklabels(payment_data['Payment Method'])

    ax.set_xlabel('Percentage of Customers', fontweight='bold')
    ax.set_ylabel('Payment Method', fontweight='bold')
    ax.set_title(
        'Customer Base and Churn Structure by Payment Method',
        fontsize=16,
        fontweight='bold'
    )

    # X-axis as percentages
    ax.set_xlim(0, 1)
    ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))
    ax.grid(axis='x', alpha=0.3)

    # Legend below the chart
    ax.legend(
        loc='upper center',
        bbox_to_anchor=(0.5, -0.12),
        ncol=2,
        frameon=False
    )

    # Percentage labels inside the bars
    for i, row in payment_data.iterrows():
        stayed = row['Stayed_pct']
        churn = row['Churn_pct']

        # label for Stayed (only if big enough)
        if stayed > 0.05:
            ax.text(
                stayed / 2,
                y_pos[i],
                f"{stayed*100:.1f}%",
                va='center',
                ha='center',
                color='white',
                fontsize=9,
                fontweight='bold'
            )

        # label for Churned (only if big enough)
        if churn > 0.05:
            ax.text(
                stayed + churn / 2,
                y_pos[i],
                f"{churn*100:.1f}%",
                va='center',
                ha='center',
                color='white',
                fontsize=9,
                fontweight='bold'
            )

    plt.tight_layout()
    plt.subplots_adjust(bottom=0.22, left=0.28, right=0.97)

    os.makedirs(output_path, exist_ok=True)
    fig.savefig(
        os.path.join(output_path, 'q8_payment_method_analysis.png'),
        dpi=300,
        bbox_inches='tight'
    )
    plt.show()

    # Key insights
    print("\nKey Insights:")
    highest_churn = payment_churn.head(1)
    lowest_churn = payment_churn.tail(1)

    print(
        f"Highest churn payment method: "
        f"{highest_churn['Payment Method'][0]} "
        f"({highest_churn['Churn_Rate'][0]:.2f}%)"
    )
    print(
        f"Lowest churn payment method: "
        f"{lowest_churn['Payment Method'][0]} "
        f"({lowest_churn['Churn_Rate'][0]:.2f}%)"
    )
    print("Recommendation: Incentivate migration to low-churn payment methods.")

    return payment_churn_fmt


#Q8 Call
payment_results = q8_payment_method_analysis(df)

"""###3.9.3-Service Dimensions and Engagement (Q9, Q11, Q12)

**Q9. What is the relationship between service bundle complexity (number of services contracted) and churn rate?**

**Justification:** Customers with multiple services may have higher switching costs and be less prone to churn.

**Analysis:** Examine how the number of services subscribed affects churn, testing if simpler or more complex bundles lead to better retention.
"""

def q9_service_bundle_complexity_analysis(df):

    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.ticker as mtick

    print("\033[1mQ9. What is the relationship between service bundle complexity (number of services contracted) and churn rate?\033[0m")

    #Define service columns
    service_columns = [
        'Phone Service', 'Multiple Lines', 'Internet Service',
        'Online Security', 'Online Backup', 'Device Protection Plan',
        'Premium Tech Support', 'Streaming TV', 'Streaming Movies', 'Streaming Music'
    ]

    #Create flag columns + service count
    df_analysis = (
        df.with_columns([
            pl.when(pl.col(col).is_in(['Yes', 'DSL', 'Fiber optic']))
              .then(1).otherwise(0).alias(col + '_flag')
            for col in service_columns
        ])
        .with_columns([
            pl.sum_horizontal([pl.col(col + '_flag') for col in service_columns]).alias('Service_Count')
        ])
    )

    #Complexity groups
    df_analysis = df_analysis.with_columns([
        pl.when(pl.col('Service_Count') <= 2)
          .then(pl.lit('Simple (1–2 services)'))
         .when(pl.col('Service_Count') <= 4)
          .then(pl.lit('Moderate (3–4 services)'))
         .when(pl.col('Service_Count') <= 6)
          .then(pl.lit('Complex (5–6 services)'))
         .otherwise(pl.lit('Very Complex (7+ services)'))
         .alias('Bundle_Complexity')
    ])

    #Aggregate metrics
    bundle_churn = (
        df_analysis
        .group_by('Bundle_Complexity')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (pl.col('Customer Status')
             .filter(pl.col('Customer Status') == 'Churned')
             .count() / pl.count('Customer ID') * 100).alias('Churn_Rate'),
            pl.col('Monthly Charge').mean().alias('Avg_Monthly_Charge'),
            pl.col('CLTV').mean().alias('Avg_CLTV')
        ])
        .sort('Total_Customers', descending=True)
    )

    #Format table for display
    bundle_churn_fmt = bundle_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_Monthly_Charge").map_elements(lambda v: f"€{v:,.2f}"),
        pl.col("Avg_CLTV").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nChurn Rate by Bundle Complexity:")
    print(bundle_churn_fmt)

    #Visualisation
    bundle_data = bundle_churn.to_pandas()
    groups = bundle_data["Bundle_Complexity"]
    x_pos = np.arange(len(groups))

    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Plot 1: Churn Rate
    axes[0].bar(x_pos, bundle_data['Churn_Rate'], color='#E63946', width=0.65)
    axes[0].set_xticks(x_pos)
    axes[0].set_xticklabels(groups, rotation=30, ha='right')
    axes[0].set_title('Churn Rate by Service Bundle Complexity', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Bundle Complexity', fontweight='bold')
    axes[0].set_ylabel('Churn Rate (%)', fontweight='bold')
    axes[0].grid(axis='y', alpha=0.3)

    for i, v in enumerate(bundle_data['Churn_Rate']):
        if v > 2:
            axes[0].text(i, v + 0.5, f"{v:.1f}%", ha='center', fontsize=9, fontweight='bold')

    # Plot 2: CLTV
    axes[1].bar(x_pos, bundle_data['Avg_CLTV'], color='#457B9D', width=0.65)
    axes[1].set_xticks(x_pos)
    axes[1].set_xticklabels(groups, rotation=30, ha='right')
    axes[1].set_title('Customer Lifetime Value by Bundle Complexity', fontsize=9, fontweight='bold')
    axes[1].set_xlabel('Bundle Complexity', fontweight='bold')
    axes[1].set_ylabel('Average CLTV (€)', fontweight='bold')
    axes[1].grid(axis='y', alpha=0.3)

    for i, v in enumerate(bundle_data['Avg_CLTV']):
        axes[1].text(i, v + (v * 0.01), f"€{v:,.0f}", ha='center', fontsize=9, fontweight='bold')

    plt.tight_layout()
    os.makedirs(output_path, exist_ok=True)
    plt.savefig(os.path.join(output_path, 'q9_bundle_complexity_analysis.png'),
                dpi=300, bbox_inches='tight')
    plt.show()

    print("\nKey Insights:")
    print("→ Service bundle complexity impacts both churn and customer value.")
    print("→ Optimise bundle offerings based on the churn–CLTV trade-off.")

    return bundle_churn_fmt, df_analysis.select(['Customer ID', 'Service_Count', 'Bundle_Complexity'])

#Call Q9
bundle_results, bundle_detail = q9_service_bundle_complexity_analysis(df)

"""**Q11. What is the impact of contract type and the use of paperless billing on customer retention?**

**Justification:** Long-term contracts and digitization may indicate different levels of commitment.

**Analysis:** Examine the combined effect of contract type and paperless billing on churn rates to identify optimal combinations.
"""

def q11_contract_paperless_analysis(df):
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.ticker as mtick

    print("\033[1mQ11. What is the impact of contract type and the use of paperless billing on customer retention?\033[0m")

    # --- Processamento dos dados ---
    contract_paperless = (
        df.group_by(['Contract', 'Paperless Billing'])
          .agg([
              pl.count('Customer ID').alias('Total_Customers'),
              (
                  pl.col('Customer Status')
                  .filter(pl.col('Customer Status') == 'Churned')
                  .count()
                  / pl.count('Customer ID') * 100
              ).alias('Churn_Rate'),
              pl.col('Monthly Charge').mean().alias('Avg_Monthly_Charge')
          ])
          .sort(['Contract', 'Paperless Billing'])
    )

    contract_paperless_fmt = contract_paperless.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_Monthly_Charge").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nChurn Rate by Contract Type and Paperless Billing:")
    print(contract_paperless_fmt)

    contract_data = contract_paperless.to_pandas()
    contract_types = contract_data['Contract'].unique()

    x = np.arange(len(contract_types))
    width = 0.35

    # --- Criar figura com apenas 1 gráfico ---
    fig, ax = plt.subplots(figsize=(9, 6))

    # Separar Paperless Yes/No
    paperless_yes = (
        contract_data[contract_data['Paperless Billing'] == 'Yes']
        .set_index('Contract')['Churn_Rate']
        .reindex(contract_types)
    )
    paperless_no = (
        contract_data[contract_data['Paperless Billing'] == 'No']
        .set_index('Contract')['Churn_Rate']
        .reindex(contract_types)
    )

    # --- Gráfico de barras ---
    ax.bar(x - width/2, paperless_yes, width, label='Paperless: Yes', color='#E63946')
    ax.bar(x + width/2, paperless_no, width, label='Paperless: No', color='#457B9D')

    # --- Labels e título ---
    ax.set_xlabel('Contract Type', fontweight='bold')
    ax.set_ylabel('Churn Rate (%)', fontweight='bold')
    ax.set_title('Churn Rate by Contract Type & Paperless Billing', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(contract_types, rotation=20, ha='right')
    ax.grid(axis='y', alpha=0.3)
    ax.legend()

    # --- Percentagens acima das barras ---
    for idx, val in enumerate(paperless_yes):
        ax.text(idx - width/2, val + 0.5, f"{val:.1f}%", ha='center', fontsize=9, fontweight='bold')

    for idx, val in enumerate(paperless_no):
        ax.text(idx + width/2, val + 0.5, f"{val:.1f}%", ha='center', fontsize=9, fontweight='bold')

    plt.tight_layout()

    # Guardar imagem
    os.makedirs(output_path, exist_ok=True)
    plt.savefig(os.path.join(output_path, 'q11_contract_paperless_analysis.png'), dpi=300, bbox_inches='tight')
    plt.show()

    # --- Insights ---
    print("\nKey Insights:")
    best_combo = contract_paperless.filter(pl.col('Churn_Rate') == pl.col('Churn_Rate').min())
    worst_combo = contract_paperless.filter(pl.col('Churn_Rate') == pl.col('Churn_Rate').max())

    print(
        f"Best combination: {best_combo['Contract'][0]} + Paperless {best_combo['Paperless Billing'][0]} "
        f"({best_combo['Churn_Rate'][0]:.2f}%)"
    )
    print(
        f"Worst combination: {worst_combo['Contract'][0]} + Paperless {worst_combo['Paperless Billing'][0]} "
        f"({worst_combo['Churn_Rate'][0]:.2f}%)"
    )

    return contract_paperless_fmt


#Call Q11
contract_paperless_results = q11_contract_paperless_analysis(df)

"""**Q12. Do customers with security and support services (Online Security, Premium Tech Support) have lower churn?**

**Justification:** Value-added services can increase satisfaction and perceived value.

**Analysis:** Evaluate how premium services (security, backup, tech support) affect customer retention and satisfaction.


"""

def q12_security_support_analysis(df):

    print("\033[1mQ12. Do customers with security and support services (Online Security, Premium Tech Support) have lower churn?\033[0m")

    import os
    import numpy as np
    import matplotlib.pyplot as plt

    # Analyse each premium service
    services = ['Online Security', 'Online Backup', 'Device Protection Plan', 'Premium Tech Support']

    service_impact = []
    for service in services:
        service_churn = (
            df.group_by(service)
              .agg([
                  pl.count('Customer ID').alias('Total_Customers'),
                  (
                      pl.col('Customer Status')
                      .filter(pl.col('Customer Status') == 'Churned')
                      .count() / pl.count('Customer ID') * 100
                  ).alias('Churn_Rate')
              ])
        )

        with_yes = service_churn.filter(pl.col(service) == 'Yes')
        with_no  = service_churn.filter(pl.col(service) == 'No')

        service_impact.append({
            'Service': service,
            'With_Service_Churn': with_yes['Churn_Rate'][0] if with_yes.height > 0 else 0.0,
            'Without_Service_Churn': with_no['Churn_Rate'][0] if with_no.height > 0 else 0.0
        })

    # Numeric summary
    service_df = pl.DataFrame(service_impact)

    # ---------- Formatted table for display ----------
    service_df_fmt = service_df.with_columns([
        pl.col("With_Service_Churn").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Without_Service_Churn").map_elements(lambda v: f"{v:.2f}%")
    ])

    print("\nChurn Rate Impact by Premium Service:")
    print(service_df_fmt)

    # ---------- Visualisation ----------
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    axes = axes.ravel()

    for idx, service in enumerate(services):
        service_data = (
            df.group_by(service)
              .agg([
                  pl.count('Customer ID').alias('Total_Customers'),
                  (
                      pl.col('Customer Status')
                      .filter(pl.col('Customer Status') == 'Churned')
                      .count() / pl.count('Customer ID') * 100
                  ).alias('Churn_Rate')
              ])
              .to_pandas()
        )

        # Ensure consistent order: No, Yes
        if service in service_data.columns:
            if set(service_data[service]) >= {'Yes', 'No'}:
                service_data = (
                    service_data.set_index(service)
                               .reindex(['No', 'Yes'])
                               .reset_index()
                )

        x = np.arange(len(service_data))
        colors = ['#E63946' if v == 'No' else '#2A9D8F' for v in service_data[service]]

        axes[idx].bar(x, service_data['Churn_Rate'], color=colors, width=0.6)
        axes[idx].set_xticks(x)
        axes[idx].set_xticklabels(service_data[service])
        axes[idx].set_xlabel(service, fontweight='bold')
        axes[idx].set_ylabel('Churn Rate (%)', fontweight='bold')
        axes[idx].set_title(f'{service} Impact on Churn', fontsize=12, fontweight='bold')
        axes[idx].grid(axis='y', alpha=0.3)

        # Add % labels above bars
        for i, v in enumerate(service_data['Churn_Rate']):
            axes[idx].text(
                i,
                v + 0.5,
                f"{v:.1f}%",
                ha='center',
                fontsize=9,
                fontweight='bold'
            )

    plt.tight_layout()
    os.makedirs(output_path, exist_ok=True)
    plt.savefig(output_path + '/q12_security_support_analysis.png',
                dpi=300, bbox_inches='tight')
    plt.show()

    # ---------- Key Insights + Bundle Calculation ----------
    print("\nKey Insights:")

    # Per-service impact (reduction in churn when service is present)
    service_df_pd = service_df.to_pandas()
    service_df_pd['Impact'] = service_df_pd['Without_Service_Churn'] - service_df_pd['With_Service_Churn']

    # Most effective individual service
    best_service = service_df_pd.loc[service_df_pd['Impact'].idxmax()]
    print(f"Most effective single service: {best_service['Service']}")
    print(f"Churn reduction (with vs without): {best_service['Impact']:.2f} percentage points")

    # --- Define "strong impact" services for bundle ---
    impact_mean = service_df_pd['Impact'].mean()
    strong_services = service_df_pd[service_df_pd['Impact'] > impact_mean]['Service'].tolist()

    if len(strong_services) == 0:
        print("\nNo services show impact above the average; cannot define a strong bundle.")
        print("Recommendation: Focus on the best single service and revisit bundle once new offers are tested.")
        return service_df

    print(f"\nServices selected for strong retention bundle (impact > mean): {strong_services}")

    # Flag customers who have ALL strong services active
    df_bundle = df.with_columns([
        pl.all_horizontal([pl.col(s) == 'Yes' for s in strong_services])
          .alias('Strong_Bundle_Active')
    ])

    bundle_impact = (
        df_bundle.group_by('Strong_Bundle_Active')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate')
        ])
    )

    # Formatted bundle impact for display
    bundle_impact_fmt = bundle_impact.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%")
    ])

    print("\nChurn Rate for Strong Retention Bundle:")
    print(bundle_impact_fmt)

    # Compute churn reduction for bundle vs non-bundle, if both groups exist
    bundle_pd = bundle_impact.to_pandas()

    if bundle_pd['Strong_Bundle_Active'].nunique() == 2:
        churn_with_bundle = float(bundle_pd.loc[bundle_pd['Strong_Bundle_Active'] == True, 'Churn_Rate'])
        churn_without_bundle = float(bundle_pd.loc[bundle_pd['Strong_Bundle_Active'] == False, 'Churn_Rate'])
        bundle_reduction = churn_without_bundle - churn_with_bundle

        print(
            f"\nChurn among customers WITH strong bundle: {churn_with_bundle:.2f}%"
        )
        print(
            f"Churn among customers WITHOUT strong bundle: {churn_without_bundle:.2f}%"
        )
        print(
            f"Churn reduction for strong bundle customers: {bundle_reduction:.2f} percentage points"
        )
    else:
        print("\nAll customers fall into the same bundle group (all have it or none have it).")
        print("Bundle comparison not meaningful in this dataset slice.")

    print("\nRecommendation:")
    print("Design and promote a premium bundle combining the strongest retention services,")
    print("and target high-risk segments with this bundle to maximise churn reduction.")

    # Return numeric DF (for further use), not formatted strings
    return service_df

#Call Q12
security_results = q12_security_support_analysis(df)

"""###3.9.4-Demographic Profile (Q15)

**Q15. Do specific demographic profiles (age, marital status, dependents) show distinct churn patterns?**

**Justification:** Different demographic segments have different needs and behaviors.

**Analysis:** Demographic segmentation, churn analysis by age, senior citizen, married, dependents.
"""

def q15_demographic_profile_analysis(df):
    import os
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.ticker as mtick

    print("\033[1mQ15. Do specific demographic profiles (age, marital status, dependents) show distinct churn patterns?\033[0m")

    # --- Tabela principal de perfis demográficos ---
    demographic_churn = (
        df.group_by(['Senior Citizen', 'Gender', 'Married'])
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate'),
            pl.col('Tenure in Months').mean().alias('Avg_Tenure'),
            pl.col('CLTV').mean().alias('Avg_CLTV'),
        ])
        .sort('Churn_Rate', descending=True)
    )

    demographic_fmt = demographic_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_Tenure").map_elements(lambda v: f"{v:.2f}"),
        pl.col("Avg_CLTV").map_elements(lambda v: f"€{v:,.2f}"),
    ])

    print("\nChurn Rate by Demographic Profile (Top 10):")
    print(demographic_fmt.head(10))

    # --- Age × Dependents (apenas tabela textual) ---
    age_dependents = (
        df.group_by(['Senior Citizen', 'Number of Dependents'])
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate')
        ])
    )

    age_dependents_fmt = age_dependents.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
    ])

    print("\nChurn Rate by Age and Dependents:")
    print(age_dependents_fmt)

    # ==========================
    #   VISUALIZAÇÕES (2 BARRAS + 1 BARRA HORIZONTAL)
    # ==========================
    fig = plt.figure(figsize=(16, 10))
    gs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.25)

    # ---------------------------------------
    # ax1: Churn por Senior Citizen × Gender
    # ---------------------------------------
    ax1 = fig.add_subplot(gs[0, 0])
    senior_gender = (
        df.group_by(['Senior Citizen', 'Gender'])
        .agg([
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate')
        ])
        .to_pandas()
    )

    senior_gender['Senior Citizen'] = senior_gender['Senior Citizen'].replace({0: "No", 1: "Yes"})
    pivot_sg = senior_gender.pivot(index='Senior Citizen', columns='Gender', values='Churn_Rate')

    x = np.arange(len(pivot_sg.index))
    genders = list(pivot_sg.columns)
    width = 0.35

    for i, gender in enumerate(genders):
        values = pivot_sg[gender].values
        ax1.bar(x + (i - 0.5) * width, values, width,
                label=gender,
                color='#E63946' if i == 0 else '#457B9D')

        # labels de percentagem
        for xi, val in zip(x + (i - 0.5) * width, values):
            ax1.text(xi, val + 0.4, f"{val:.1f}%", ha='center',
                     va='bottom', fontsize=9, fontweight='bold')

    ax1.set_xticks(x)
    ax1.set_xticklabels(pivot_sg.index, fontweight='bold')
    ax1.set_xlabel('Senior Citizen Status', fontweight='bold')
    ax1.set_ylabel('Churn Rate (%)', fontweight='bold')
    ax1.set_title('Churn Rate by Age × Gender', fontsize=12, fontweight='bold')
    ax1.yaxis.set_major_formatter(mtick.PercentFormatter())
    ax1.grid(axis='y', alpha=0.3)
    ax1.legend(title='Gender')

    # ---------------------------------------
    # ax2: Churn por Married × Number of Dependents (BARRAS, sem heatmap)
    # ---------------------------------------
    ax2 = fig.add_subplot(gs[0, 1])
    married_dependents = (
        df.group_by(['Married', 'Number of Dependents'])
        .agg([
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate')
        ])
        .to_pandas()
    )

    married_dependents['Married'] = married_dependents['Married'].replace({0: "No", 1: "Yes"})
    pivot_md = married_dependents.pivot(
        index='Number of Dependents',
        columns='Married',
        values='Churn_Rate'
    ).sort_index()

    dep_values = pivot_md.index
    x2 = np.arange(len(dep_values))
    married_status = list(pivot_md.columns)
    width2 = 0.35

    colors_md = {'No': '#457B9D', 'Yes': '#E9C46A'}

    for i, m_status in enumerate(married_status):
        vals = pivot_md[m_status].values
        ax2.bar(x2 + (i - 0.5) * width2, vals, width2,
                label=f"Married: {m_status}",
                color=colors_md.get(m_status, '#2A9D8F'))

        for xi, val in zip(x2 + (i - 0.5) * width2, vals):
            ax2.text(xi, val + 0.4, f"{val:.1f}%", ha='center',
                     va='bottom', fontsize=9, fontweight='bold')

    ax2.set_xticks(x2)
    ax2.set_xticklabels(dep_values, fontweight='bold')
    ax2.set_xlabel('Number of Dependents', fontweight='bold')
    ax2.set_ylabel('Churn Rate (%)', fontweight='bold')
    ax2.set_title('Churn by Marital Status × Dependents', fontsize=12, fontweight='bold')
    ax2.yaxis.set_major_formatter(mtick.PercentFormatter())
    ax2.grid(axis='y', alpha=0.3)
    ax2.legend(title='Profile')

    # ---------------------------------------
    # ax3: Top 15 perfis demográficos de maior risco (horizontal)
    # ---------------------------------------
    ax3 = fig.add_subplot(gs[1, :])
    top15 = demographic_churn.head(15).to_pandas()
    top15['Senior Citizen'] = top15['Senior Citizen'].replace({0: "No", 1: "Yes"})
    top15['Married'] = top15['Married'].replace({0: "No", 1: "Yes"})
    top15['Profile'] = (
        top15['Senior Citizen'] + " / " +
        top15['Gender'] + " / " +
        top15['Married']
    )

    ax3.barh(top15['Profile'], top15['Churn_Rate'], color='#E63946')
    ax3.set_xlabel('Churn Rate (%)', fontweight='bold')
    ax3.set_ylabel('Profile (Senior / Gender / Married)', fontweight='bold')
    ax3.set_title('Top 15 Risk Demographic Profiles', fontsize=12, fontweight='bold')
    ax3.xaxis.set_major_formatter(mtick.PercentFormatter())
    ax3.grid(axis='x', alpha=0.3)
    ax3.invert_yaxis()

    plt.tight_layout()
    os.makedirs(output_path, exist_ok=True)
    plt.savefig(output_path + '/q15_demographic_profile_analysis.png',
                dpi=300, bbox_inches='tight')
    plt.show()

    # --- Insights texto ---
    print("\nKey Insights:")
    highest_risk = demographic_churn.head(1)

    print(
        f"Highest risk profile: Senior={highest_risk['Senior Citizen'][0]}, "
        f"Gender={highest_risk['Gender'][0]}, Married={highest_risk['Married'][0]}"
    )
    print(f"Churn rate: {highest_risk['Churn_Rate'][0]:.2f}%")
    print("Recommendation: Prioritise retention programmes for high-risk demographic segments.")

    return demographic_fmt


#Call Q15
demographic_results = q15_demographic_profile_analysis(df)

"""###3.9.5-Usage and Behavioural Analisys (Q20)

**Q20. Do customers with streaming services (Streaming TV, Movies, Music) behave differently in relation to churn?**

**Justification:** Streaming services can increase engagement and dependence on the platform.

**Analysis:** Evaluate how streaming service subscriptions (TV, Movies, Music)
affect customer retention and engagement.
"""

def q20_streaming_services_analysis(df):
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import os

    print("\033[1mQ20. Do customers with streaming services (Streaming TV, Movies, Music) behave differently in relation to churn?\033[0m")

    streaming_services = ['Streaming TV', 'Streaming Movies', 'Streaming Music']

    streaming_impact = []
    for service in streaming_services:
        service_churn = (
            df.group_by(service)
            .agg([
                pl.count('Customer ID').alias('Total_Customers'),
                (
                    pl.col('Customer Status')
                    .filter(pl.col('Customer Status') == 'Churned')
                    .count() / pl.count('Customer ID') * 100
                ).alias('Churn_Rate')
            ])
        )

        with_service = service_churn.filter(pl.col(service) == 'Yes')
        without_service = service_churn.filter(pl.col(service) == 'No')

        streaming_impact.append({
            'Service': service,
            'With_Service_Churn': float(with_service['Churn_Rate'][0]) if with_service.height else 0.0,
            'Without_Service_Churn': float(without_service['Churn_Rate'][0]) if without_service.height else 0.0,
            'Impact': float(without_service['Churn_Rate'][0] - with_service['Churn_Rate'][0])
            if with_service.height and without_service.height else 0.0
        })

    streaming_df = pl.DataFrame(streaming_impact)

    # ---- Format for printing ----
    streaming_df_fmt = streaming_df.with_columns([
        pl.col("With_Service_Churn").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Without_Service_Churn").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Impact").map_elements(lambda v: f"{v:.2f} pp")
    ])

    print("\nStreaming Services Impact on Churn:")
    print(streaming_df_fmt)

    df_analysis = df.with_columns([
        (
            (pl.col('Streaming TV') == 'Yes').cast(pl.Int8) +
            (pl.col('Streaming Movies') == 'Yes').cast(pl.Int8) +
            (pl.col('Streaming Music') == 'Yes').cast(pl.Int8)
        ).alias('Streaming_Count')
    ])

    streaming_count_churn = (
        df_analysis
        .group_by('Streaming_Count')
        .agg([
            pl.count('Customer ID').alias('Total_Customers'),
            (
                pl.col('Customer Status')
                .filter(pl.col('Customer Status') == 'Churned')
                .count() / pl.count('Customer ID') * 100
            ).alias('Churn_Rate'),
            pl.col('Monthly Charge').mean().alias('Avg_Monthly_Charge'),
            pl.col('CLTV').mean().alias('Avg_CLTV')
        ])
        .sort('Streaming_Count')
    )

    # ---- Format for printing ----
    streaming_count_fmt = streaming_count_churn.with_columns([
        pl.col("Total_Customers").map_elements(lambda v: f"{v:,d}"),
        pl.col("Churn_Rate").map_elements(lambda v: f"{v:.2f}%"),
        pl.col("Avg_Monthly_Charge").map_elements(lambda v: f"€{v:,.2f}"),
        pl.col("Avg_CLTV").map_elements(lambda v: f"€{v:,.2f}")
    ])

    print("\nChurn Rate by Number of Streaming Services:")
    print(streaming_count_fmt)


    #Visualization
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.ravel()

    # Plot 1 – With vs Without comparison
    streaming_data = streaming_df.to_pandas()
    x = np.arange(len(streaming_data))
    width = 0.35

    axes[0].bar(
        x - width/2,
        streaming_data['With_Service_Churn'],
        width,
        label='With Service',
        color='#2A9D8F'
    )
    axes[0].bar(
        x + width/2,
        streaming_data['Without_Service_Churn'],
        width,
        label='Without Service',
        color='#E63946'
    )
    axes[0].set_xticks(x)
    axes[0].set_xticklabels([s.replace('Streaming ', '') for s in streaming_data['Service']])
    axes[0].set_title('Churn Rate: With vs Without Streaming Services', fontsize=10, fontweight='bold')
    axes[0].set_xlabel('Streaming Service', fontweight='bold')
    axes[0].set_ylabel('Churn Rate (%)', fontweight='bold')
    axes[0].legend()
    axes[0].grid(axis='y', alpha=0.3)

    # Add labels
    for i, row in streaming_data.iterrows():
        axes[0].text(i - width/2, row['With_Service_Churn'] + 0.4, f"{row['With_Service_Churn']:.1f}%",
                     ha='center', fontsize=9)
        axes[0].text(i + width/2, row['Without_Service_Churn'] + 0.4, f"{row['Without_Service_Churn']:.1f}%",
                     ha='center', fontsize=9)

    # Plot 2 – Impact barh
    axes[1].barh(streaming_data['Service'], streaming_data['Impact'], color='#457B9D')
    axes[1].set_title('Churn Reduction Impact by Service', fontsize=10, fontweight='bold')
    axes[1].set_xlabel('Churn Reduction (pp)', fontweight='bold')
    axes[1].set_ylabel('Service', fontweight='bold')
    axes[1].grid(axis='x', alpha=0.3)

    # Add labels
    for i, row in streaming_data.iterrows():
        axes[1].text(row['Impact'] + 0.1, row['Service'], f"{row['Impact']:.2f} pp",
                     va='center', fontsize=9, fontweight='bold')

    # Plot 3 – Churn rate by count
    count_data = streaming_count_churn.to_pandas()
    axes[2].plot(
        count_data['Streaming_Count'],
        count_data['Churn_Rate'],
        marker='o',
        linewidth=2,
        markersize=10,
        color='#E63946'
    )
    axes[2].set_title('Churn Rate by Number of Streaming Services', fontsize=10, fontweight='bold')
    axes[2].set_xlabel('Number of Streaming Services', fontweight='bold')
    axes[2].set_ylabel('Churn Rate (%)', fontweight='bold')
    axes[2].grid(True, alpha=0.3)

    # Plot 4 – CLTV by count
    axes[3].bar(
        count_data['Streaming_Count'],
        count_data['Avg_CLTV'],
        color='#2A9D8F'
    )
    axes[3].set_title('Customer Lifetime Value by Number of Streaming Services', fontsize=10, fontweight='bold')
    axes[3].set_xlabel('Number of Streaming Services', fontweight='bold')
    axes[3].set_ylabel('Average CLTV (€)', fontweight='bold')
    axes[3].grid(axis='y', alpha=0.3)

    # Add CLTV labels
    for i, v in enumerate(count_data['Avg_CLTV']):
        axes[3].text(count_data['Streaming_Count'][i], v + (v * 0.01), f"€{v:,.0f}",
                     ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    os.makedirs(output_path, exist_ok=True)
    plt.savefig(os.path.join(output_path, 'q20_streaming_services_analysis.png'),
                dpi=300, bbox_inches='tight')
    plt.show()

    print("\nKey Insights:")
    best_service = streaming_data.loc[streaming_data['Impact'].idxmax()]
    print(f"Most effective service: {best_service['Service']} (reduces churn by {best_service['Impact']:.2f} pp)")

    if 0 in count_data['Streaming_Count'].values:
        churn0 = float(count_data.loc[count_data['Streaming_Count'] == 0, 'Churn_Rate'])
        print(f"Churn with 0 streaming services: {churn0:.2f}%")

    if 3 in count_data['Streaming_Count'].values:
        churn3 = float(count_data.loc[count_data['Streaming_Count'] == 3, 'Churn_Rate'])
        print(f"Churn with 3 streaming services: {churn3:.2f}%")

    print("Recommendation: Bundle streaming services to increase engagement and reduce churn.")

    return streaming_df_fmt, streaming_count_fmt


#Call Q20
streaming_impact, streaming_count = q20_streaming_services_analysis(df)

"""##3.10-DashBords For Additional B. Questions

###3.10.1 (Contract & Tenure) vs Churn
"""

import pandas as pd

dashboard_data = df.to_pandas().copy()

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Churn Rate by Contract Type',
                    'Churn Rate by Tenure Group',
                    'Monthly Charge Distribution by Churn',
                    'CLTV Distribution by Churn'),
    specs=[[{'type': 'bar'}, {'type': 'bar'}],
           [{'type': 'box'}, {'type': 'box'}]]
)

# 1. Churn by Contract Type
contract_churn = dashboard_data.groupby('Contract')['Churn Label'].apply(
    lambda x: (x == 'Yes').sum() / len(x) * 100
).reset_index()
contract_churn.columns = ['Contract', 'Churn_Rate']

fig.add_trace(
    go.Bar(x=contract_churn['Contract'], y=contract_churn['Churn_Rate'],
           name='Contract Type', marker_color='indianred'),
    row=1, col=1
)

# 2. Churn by Tenure Group (from Q4 analysis)
tenure_groups = pd.cut(dashboard_data['Tenure in Months'],
                       bins=[0, 6, 12, 24, 36, 72],
                       labels=['0-6m', '6-12m', '12-24m', '24-36m', '36m+'])
tenure_churn = dashboard_data.groupby(tenure_groups)['Churn Label'].apply(
    lambda x: (x == 'Yes').sum() / len(x) * 100
).reset_index()
tenure_churn.columns = ['Tenure_Group', 'Churn_Rate']

fig.add_trace(
    go.Bar(x=tenure_churn['Tenure_Group'], y=tenure_churn['Churn_Rate'],
           name='Tenure in Group', marker_color='lightseagreen'),
    row=1, col=2
)

# 3. Monthly Charge by Churn
fig.add_trace(
    go.Box(x=dashboard_data['Churn Label'], y=dashboard_data['Monthly Charge'],
           name='Monthly Charge', marker_color='mediumpurple'),
    row=2, col=1
)

# 4. CLTV by Churn (from Q6 analysis)
fig.add_trace(
    go.Box(x=dashboard_data['Churn Label'], y=dashboard_data['CLTV'],
           name='CLTV', marker_color='gold'),
    row=2, col=2
)

# Update layout
fig.update_xaxes(title_text="Contract Type", row=1, col=1)
fig.update_xaxes(title_text="Tenure Group", row=1, col=2)
fig.update_xaxes(title_text="Churn Status", row=2, col=1)
fig.update_xaxes(title_text="Churn Status", row=2, col=2)

fig.update_yaxes(title_text="Churn Rate (%)", row=1, col=1)
fig.update_yaxes(title_text="Churn Rate (%)", row=1, col=2)
fig.update_yaxes(title_text="Monthly Charge ($)", row=2, col=1)
fig.update_yaxes(title_text="CLTV ($)", row=2, col=2)

fig.update_layout(height=800, showlegend=False,
                  title_text="Churn Analysis Dashboard - Key Metrics",
                  title_font_size=20)

fig.write_html(output_path + '/churn_dashboard_main.html')
fig.show()

print("\nMain churn dashboard created and saved")

"""###3.10.2-(Payment Meth & Serv Bundle) vs Churn"""

# Dashboard for additional business questions insights

# Define which columns count as services
service_cols = [
    'Phone Service',
    'Multiple Lines',
    'Internet Service',
    'Online Security',
    'Online Backup',
    'Device Protection Plan',
    'Premium Tech Support',
    'Streaming TV',
    'Streaming Movies',
    'Streaming Music',
    'Unlimited Data'
]

# Create Number_of_Services: count how many "Yes" each customer has
dashboard_data['Number_of_Services'] = dashboard_data[service_cols].eq('Yes').sum(axis=1)


fig2 = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Churn Rate by Payment Method (Q8)',
                    'Churn Rate by Service Bundle Complexity (Q9)',
                    'Payment Method Distribution',
                    'Service Count Distribution'),
    specs=[[{'type': 'bar'}, {'type': 'bar'}],
           [{'type': 'pie'}, {'type': 'histogram'}]]
)

# 1. Churn by Payment Method (Q8)
payment_churn = dashboard_data.groupby('Payment Method')['Churn Label'].apply(
    lambda x: (x == 'Yes').sum() / len(x) * 100
).reset_index()
payment_churn.columns = ['Payment Method', 'Churn_Rate']

fig2.add_trace(
    go.Bar(x=payment_churn['Payment Method'], y=payment_churn['Churn_Rate'],
           marker_color='crimson'),
    row=1, col=1
)

# 2. Churn by Service Bundle Complexity (Q9)
# Assuming you have a 'Number_of_Services' column from Q9 analysis
if 'Number_of_Services' in dashboard_data.columns:
    bundle_churn = dashboard_data.groupby('Number_of_Services')['Churn Label'].apply(
        lambda x: (x == 'Yes').sum() / len(x) * 100
    ).reset_index()
    bundle_churn.columns = ['Number_of_Services', 'Churn_Rate']

    fig2.add_trace(
        go.Bar(x=bundle_churn['Number_of_Services'], y=bundle_churn['Churn_Rate'],
               marker_color='darkorange'),
        row=1, col=2
    )

# 3. Payment Method Distribution
payment_dist = dashboard_data['Payment Method'].value_counts()
fig2.add_trace(
    go.Pie(labels=payment_dist.index, values=payment_dist.values,
           marker_colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']),
    row=2, col=1
)

# 4. Service Count Distribution
if 'Number_of_Services' in dashboard_data.columns:
    fig2.add_trace(
        go.Histogram(x=dashboard_data['Number_of_Services'],
                     marker_color='steelblue', nbinsx=10),
        row=2, col=2
    )

# Update layout
fig2.update_xaxes(title_text="Payment Method", row=1, col=1)
fig2.update_xaxes(title_text="Number of Services", row=1, col=2)
fig2.update_xaxes(title_text="Number of Services", row=2, col=2)

fig2.update_yaxes(title_text="Churn Rate (%)", row=1, col=1)
fig2.update_yaxes(title_text="Churn Rate (%)", row=1, col=2)
fig2.update_yaxes(title_text="Count", row=2, col=2)

fig2.update_layout(height=800, showlegend=False,
                   title_text="Payment & Services Analysis Dashboard (Q8 & Q9)",
                   title_font_size=20)

fig2.write_html(output_path + '/payment_services_dashboard.html')
fig2.show()

print("\nPayment & Services dashboard created and saved")

"""#4.Feature Engineering

###4.1-Creating Composite Features

Based on our project goals and the data analysis from previous sections, we will now create the following composite features.

4.1.1 - Customer Longevity Ratio  
4.1.2 - Average Monthly Spend  
4.1.3 - Service Bundle Complexity Index  
4.1.4 - Revenue per Service  
4.1.5 - Has Dependents (binary)  
4.1.6 - Is Heavy User (based on data download)  
4.1.7 - CLTV per Month  
4.1.8 - Has Premium Services  
4.1.9 - Streaming Services Count  
4.1.10 - Contract Value (encoding contract types)    
4.1.11 - Customer Engagement Score (composite)  
4.1.12 - Population Density Category  

  
The code provides detailed information about each feature, including the formula used to calculate each one.
"""

print("Creating new features (Composite Features)\n")
df_fe = df.clone()

#4.1.1 - Customer Longevity Ratio
df_fe = df_fe.with_columns(
    (pl.col("Tenure in Months") / pl.col("Age")).alias("Longevity_Ratio")
)

print("Longevity_Ratio (Tenure / Age): Done")

#4.1.2 - Average Monthly Spend
df_fe = df_fe.with_columns(
    (pl.col("Total Revenue") / (pl.col("Tenure in Months") + 1))
    .alias("Avg_Monthly_Spend")
)

print("Avg_Monthly_Spend (Total Revenue / Tenure): Done")

# 4.1.3 - Service Bundle Complexity Index
service_cols = [
    "Phone Service", "Internet Service", "Online Security", "Online Backup",
    "Device Protection Plan", "Premium Tech Support", "Streaming TV",
    "Streaming Movies", "Streaming Music", "Unlimited Data"
]

df_fe = df_fe.with_columns(
    pl.sum_horizontal([
        (pl.col(c) == "Yes").cast(pl.Int8) for c in service_cols
    ]).alias("Service_Bundle_Count")
)

print("Service_Bundle_Count (Number of services subscribed): Done")

# 4.1.4 - Revenue per Service
df_fe = df_fe.with_columns(
    (pl.col("Total Revenue") / (pl.col("Service_Bundle_Count") + 1))
    .alias("Revenue_per_Service")
)

print("Revenue_per_Service (Total Revenue / Service Count): Done")

# 4.1.5 - Has Dependents (binary)
df_fe = df_fe.with_columns(
    (pl.col("Number of Dependents") > 0)
    .cast(pl.Int8)
    .alias("Has_Dependents")
)

print("Has_Dependents (Binary indicator): Done")

# 4.1.6 - Is an Heavy User (based on data download)
median_download = df_fe.select(pl.col("Avg Monthly GB Download").median()).item()

df_fe = df_fe.with_columns(
    (pl.col("Avg Monthly GB Download") > median_download)
    .cast(pl.Int8)
    .alias("Is_Heavy_User")
)

print("Is_Heavy_User (Above median data usage): Done")

# 4.1.7 - CLTV per Month
"""
Customer Lifetime Value (CLTV) represents the total revenue (or profit)
a company expects to earn from a customer per month
"""
df_fe = df_fe.with_columns(
    (pl.col("CLTV") / (pl.col("Tenure in Months") + 1))
    .alias("CLTV_per_Month")
)

print("CLTV_per_Month (CLTV / Tenure): Done")

# 4.1.8 - Has Premium Services
premium_services = [
    "Online Security", "Online Backup",
    "Device Protection Plan", "Premium Tech Support"
]

df_fe = df_fe.with_columns(
    pl.any_horizontal([
        (pl.col(c) == "Yes") for c in premium_services
    ]).cast(pl.Int8).alias("Has_Premium_Services")
)

print("Has_Premium_Services (Any premium service): Done")

# 4.1.9 - Streaming Services Count
streaming_cols = ["Streaming TV", "Streaming Movies", "Streaming Music"]

df_fe = df_fe.with_columns(
    pl.sum_horizontal([
        (pl.col(c) == "Yes").cast(pl.Int8) for c in streaming_cols
    ]).alias("Streaming_Count")
)

print("Streaming_Count (Number of streaming services): Done")

# 4.1.10 - Contract Value (encoding contract types)
contract_value_map = {"Month-to-Month": 1, "One Year": 12, "Two Year": 24}

df_fe = df_fe.with_columns(
    pl.col("Contract")
    .replace(contract_value_map)
    .cast(pl.Int8)
    .alias("Contract_Value")
)

print("Contract Value (encoding contract types): Done")

# 4.1.11 - Customer Engagement Score (a kind of fidelization score)
tenure_max = df_fe.select(pl.col("Tenure in Months").max()).item()
referrals_max = df_fe.select(pl.col("Number of Referrals").max()).item()
services_max = df_fe.select(pl.col("Service_Bundle_Count").max()).item()
contract_max  = df_fe.select(pl.col("Contract_Value").max()).item()

df_fe = df_fe.with_columns(
    (
        (pl.col("Tenure in Months") / tenure_max) * 0.3 +
        (pl.col("Number of Referrals") / (referrals_max + 1)) * 0.2 +
        (pl.col("Service_Bundle_Count") / services_max) * 0.3 +
        (pl.col("Contract_Value") / contract_max)       * 0.2
    ).alias("Engagement_Score")
)

print("Customer Engagement Score: Done")

# 4.1.12 - Population Density Category
df_fe = df_fe.with_columns(
    pl.when((pl.col("Population") > 0) & (pl.col("Population") <= 30_000)).then(pl.lit("Low"))
     .when((pl.col("Population") > 30_000) & (pl.col("Population") <= 50_000)).then(pl.lit("Medium"))
     .when((pl.col("Population") > 50_000) & (pl.col("Population") <= 100_000)).then(pl.lit("High"))
     .otherwise(pl.lit(None))
     .cast(pl.Utf8)  # or .cast(pl.Categorical)
     .alias("Population_Density")
)

print("Population_Density (Categorical): Done")

#Save dataset with new features
df_fe.write_csv(output_path + "telco_churn_new_features.csv")

print(f"Dataset with new feature saved to: {output_path}telco_churn_new_features.csv")

"""###4.2-New Feature Importance (Correlation with Churn)

"""

new_features = [
    "Longevity_Ratio", "Avg_Monthly_Spend", "Service_Bundle_Count",
    "Revenue_per_Service", "CLTV_per_Month", "Engagement_Score", "Contract_Value"
]

df_fe = df_fe.with_columns(
    (pl.col("Churn Label") == "Yes").cast(pl.Int8).alias("Churn_Binary")
)

corr_row = df_fe.select([
    pl.corr(pl.col(feat), pl.col("Churn_Binary"), method="spearman")

    for feat in new_features
])

corr_with_churn = (
    corr_row
    .melt(variable_name="Feature", value_name="Correlation")
    .sort("Correlation", descending=True)
)

corr_fmt = corr_with_churn.with_columns([
    pl.col("Correlation").map_elements(lambda v: f"{v:.4f}")
])

print("\nNew Features Correlation with Churn (sorted):\n")
print(corr_fmt)

import matplotlib.pyplot as plt
import polars as pl
import numpy as np

corr_pd = corr_with_churn.to_pandas().sort_values("Correlation", ascending=True)

colors = np.where(corr_pd["Correlation"] < 0, "#4CAF50", "#F44336")

#Plot
plt.figure(figsize=(9, 5))
bars = plt.barh(
    corr_pd["Feature"],
    corr_pd["Correlation"],
    color=colors,
    edgecolor="black"
)

plt.title("New Features Correlation with Churn", fontsize=14, weight="bold", pad=12)
plt.xlabel("Correlation Coefficient (Spearman)", fontsize=10)
plt.ylabel("Feature", fontsize=10)
plt.axvline(0, color="black", linestyle="--", linewidth=1)

# Annotate bars with correlation values
for bar, value in zip(bars, corr_pd["Correlation"]):
    plt.text(
        value + (0.015 if value >= 0 else -0.015),
        bar.get_y() + bar.get_height() / 2,
        f"{value:.2f}",
        va="center",
        ha="left" if value >= 0 else "right",
        fontsize=8
    )

plt.grid(axis="x", linestyle="--", alpha=0.6)
plt.tight_layout()
plt.show()

"""The correlation table gives a clear quantitative view of how each engineered feature relates to churn probability. Lets try to explain each one with a little more detail:  

**CLTV_per_Month (0.34):** Positive and moderate — customers generating higher lifetime value per month tend to churn slightly more. This may indicate that some high-value customers are price-sensitive or expect premium service quality; when disappointed, they leave.  

**Avg_Monthly_Spend (0.04):** Almost neutral — spending alone doesn’t explain churn. Customers paying more aren’t necessarily more or less likely to churn.

**Service_Bundle_Count (0.01):** Essentially no relationship — the number of subscribed services doesn’t predict churn, suggesting customers churn regardless of how many services they have.

**Revenue_per_Service (-0.34)**: Moderate negative — customers who derive more revenue per service are less likely to churn. This could reflect better perceived value or usage intensity.  

**Longevity_Ratio (-0.38):** Moderate negative — customers whose tenure relative to age is higher are more loyal. This makes sense: longer relationships imply higher retention.  

**Engagement_Score (-0.38)**: Moderately negative relationship — highly engaged customers, who stay longer and use more services, show a much lower churn tendency.

**Contract_Value (-0.45):** Strong negative — the longer the contract (one-year/two-year), the lower the churn. This is a key business insight: long-term contracts are an effective retention mechanism.

###4.3-Major Insights

**1. Engagement_Score** and **Contract_Value** are the most powerful anti-churn indicators. They should feature prominently in any churn prediction model.  

**2. CLTV_per_Month** shows an interesting positive correlation: some high-value customers are at higher churn risk. These customers may be “attractive defectors” and they should be the target for proactive retention strategies.  

**3.** The weak correlations for **Avg_Monthly_Spend** and **Service_Bundle_Count** indicate that volume alone doesnt drive loyalty.

**4. Longevity_Ratio** and **Revenue_per_Service** add moderate explanatory power and complement the stronger features.

###4.4-Costumer Strategy

**Customer segmentation:** Target high CLTV, high spend, but low engagement customers with personalized retention actions.

**Contract strategy:** Encourage upgrades from monthly to annual contracts; it has measurable impact on churn.

**Predictive modeling:** Keep Engagement_Score and Contract_Value as key predictors; consider interaction terms with CLTV for richer insights.

#5.Preditive Modelling

As prediction models, and because our dataset is not very big (only 7.043 observations) we choose to start by use the following models:

*   Logistic Regression;
*   Random Forrest, and;
*   XGBoost (Gradient Boosting).

These three models represent a balanced and complementary set of algorithms that are widely established in churn prediction and customer analytics.

**Logistic Regression:** It will be used as baseline, offering clear coefficient-based insights and robust performance on linearly separable structures.  

**Random Forest:** Introduces non-linear modelling capacity and feature interaction, allowing the detection of complex behavioural patterns that linear models may miss.  

**XGBoost:** Extends this further with gradient boosting, which is recognised as one of the most effective techniques for tabular business data, providing superior accuracy, strong calibration, and compatibility with TreeSHAP for explainability.  

Together, these three models cover the main modelling paradigms used in industry for churn prediction—linear, bagging, and boosting—ensuring a rigorous comparison and a defensible model selection process.

###5.1-Preparing Data For Modeling
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import recall_score, f1_score, precision_score, precision_recall_curve

print("\nPreparing data for modeling...\n")

# Define categorical and numerical features
categorical_features = [
    "Gender", "Senior Citizen", "Married", "Dependents",
    "Contract", "Paperless Billing", "Payment Method",
    "Internet Type", "Phone Service", "Multiple Lines",
    "Online Security", "Online Backup", "Device Protection Plan",
    "Premium Tech Support", "Streaming TV", "Streaming Movies",
    "Streaming Music", "Unlimited Data"
]

numerical_features = [
    "Age", "Number of Dependents", "Tenure in Months",
    "Monthly Charge", "CLTV", "Number of Referrals", "Avg Monthly GB Download",
    "Population", "Longevity_Ratio", "Avg_Monthly_Spend",
    "Service_Bundle_Count", "Revenue_per_Service",
    "Engagement_Score", "Contract_Value", "Streaming_Count"
]

# Check for possible missing_cols in df_fe
missing_cols = [col for col in categorical_features + numerical_features if col not in df_fe.columns]
if missing_cols:
    print(f"Missing columns in dataset: {missing_cols}")
else:
    print("All modeling feature columns verified in DataFrame.")

# Create a clean dataset for modeling
df_model = df_fe.clone()

print("\nHandling missing values...\n")

# Fill numeric null values with column median
for col in numerical_features:
    median_val = df_model.select(pl.col(col).median()).item()
    df_model = df_model.with_columns(
        pl.col(col).fill_null(median_val)
    )

# Fill categorical columns with their mode (most frequent value)
for col in categorical_features:
    mode_val = (
        df_model.select(pl.col(col).mode().first())
        .to_series()[0]
        if df_model.select(pl.col(col).is_not_null().sum()).item() > 0
        else None
    )
    if mode_val is not None:
        df_model = df_model.with_columns(
            pl.col(col).fill_null(mode_val)
        )

print("Missing values handled (median for numeric, mode for categorical).\n")

print("Encoding categorical variables...\n")

for col in categorical_features:
    unique_vals = df_model.select(pl.col(col).unique()).to_series().to_list()
    mapping = {val: idx for idx, val in enumerate(sorted(unique_vals))}

    df_model = df_model.with_columns(
        pl.col(col).replace(mapping).cast(pl.Int32).alias(col + "_encoded")
    )

print("Categorical variables encoded as numeric codes.\n")

print(f"Dataframe with results is df_model.\n")

import polars as pl

#Data dictionary
cols = df_model.columns

data_dict = pl.DataFrame({
    "Column": cols,
    "Data_Type": [str(dt) for dt in df_model.dtypes],
    "Non_Null_Count": [df_model[col].drop_nulls().len() for col in cols],
    "Unique_Values": [df_model[col].n_unique() for col in cols],
})

print("\nData Dictionary (df_model)\n")
print(data_dict)

save_file = output_path + "/df_model_data_dictionary.csv"
data_dict.write_csv(str(save_file))

print(f"\nData dictionary saved to {save_file}")

"""###5.2-Preparing Feature Matrix and Target"""

print("\nPreparing feature matrix and target...\n")

encoded_categorical = [col + "_encoded" for col in categorical_features]

X = df_model.select(numerical_features + encoded_categorical)
y = df_model.select("Churn_Binary")

print(f"Feature matrix shape: {X.shape}")

# Convert to pandas for sklearn and compute distribution
X_pd = X.to_pandas()
y_pd = y.to_pandas().squeeze()   # single-column DF -> Series
print(f"Target distribution: {y_pd.value_counts().to_dict()}\n")

print("Splitting data into train and test sets...")
X_train, X_test, y_train, y_test = train_test_split(
    X_pd, y_pd, test_size=0.2, random_state=42, stratify=y_pd
)
print(f"Training set: {X_train.shape}")
print(f"Test set: {X_test.shape}")

print("\nScaling numerical features...")
scaler = StandardScaler()
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()
X_train_scaled[numerical_features] = scaler.fit_transform(X_train[numerical_features])
X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])

print("\nNumerical features scaled and data ready for modeling.\n")

"""###5.3-Training Predictive Models"""

print("\nTraining predictive models...")

models = {}
predictions = {}
probabilities = {}

"""####5.3.1-Training Logistic Regression"""

print("\nTraining Logistic Regression...")
lr_model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')
lr_model.fit(X_train_scaled, y_train)
models['Logistic Regression'] = lr_model
predictions['Logistic Regression'] = lr_model.predict(X_test_scaled)
probabilities['Logistic Regression'] = lr_model.predict_proba(X_test_scaled)[:, 1]
print("\n  Logistic Regression trained")

"""####5.3.2-Training Random Forest"""

print("\n  Training Random Forest...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)
rf_model.fit(X_train, y_train)
models['Random Forest'] = rf_model
predictions['Random Forest'] = rf_model.predict(X_test)
probabilities['Random Forest'] = rf_model.predict_proba(X_test)[:, 1]
print("\n  Random Forest trained")

"""####5.3.3-Training XGBoost"""

print("\n  Training XGBoost...")
# Calculate scale_pos_weight for imbalanced data
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
xgb_model = XGBClassifier(n_estimators=100, random_state=42, scale_pos_weight=scale_pos_weight,
                         learning_rate=0.1, max_depth=5, n_jobs=-1)
xgb_model.fit(X_train, y_train)
models['XGBoost'] = xgb_model
predictions['XGBoost'] = xgb_model.predict(X_test)
probabilities['XGBoost'] = xgb_model.predict_proba(X_test)[:, 1]
print("\n  XGBoost trained")

print(predictions.keys())
print(models.keys())

"""#6.Model's Evaluation

For the churn project, the recall level is extremely important. Recall measures how many true churners our models can detect. The higher, the better.

False negatives (missed churners) are usually expensive because we lose customers who can be maintained with low-cost targeted actions. False positives (flagging non-churners) are less damaging, but still costly because we target and spend resources on customers who don't intend to leave us.  

Based on that we explicitly had a **target Recall >= 0.80** as the core metric to evaluate our three models.

###6.1-Models Performance Comparison
"""

results = []
for model_name in models.keys():
    y_pred = predictions[model_name]
    y_prob = probabilities[model_name]

    # Calculate metrics
    accuracy = (y_pred == y_test).mean()
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)

    results.append({
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'ROC-AUC': roc_auc
    })

    print(f"\n{model_name}:")
    print(f"  - Accuracy: {accuracy:.4f}")
    print(f"  - Precision: {precision:.4f}")
    print(f"  - Recall: {recall:.4f} {'MEETS TARGET (>0.80)' if recall > 0.80 else 'Below target'}")
    print(f"  - F1-Score: {f1:.4f}")
    print(f"  - ROC-AUC: {roc_auc:.4f}")

# Create results DataFrame (Polars)
results_df = pl.DataFrame(results)

# Save to CSV
save_file = output_path + "/model_comparison.csv"
results_df.write_csv(save_file)
print(f"\nModel comparison saved: {save_file}")

"""###6.2-Model Performance Analysis

Looking at the numbers above we can constact the Random Forest is below target Recal constraint. Logistic Regression has the best recall, but the recall of XGBoost is still above threshold and comes with better balancing of all the other metrics.

Looking at the numbers above, we can conclude that the Random Forest is below our imposed **Target Recall constraint**. Logistic Regression has the best recall, but XGBoost's recall is still above the threshold and this model provides better balance across all the other metrics. In fact, although Logistic Regression delivered the highest Recall, it did so with noticeably lower Precision, resulting in a weaker F1-Score and an increased risk of false positives. In contrast, XGBoost achieved the best overall balance between Precision and Recall (F1-Score = 0.7049) and delivered the strongest ranking performance (ROC-AUC = 0.9106), indicating superior discrimination between churners and non-churners.

This indicates that **XGBoost it is more capable of separating churners from non-churners across thresholds**.

On top of that XGBoost usually is the best choice for churn because:

*   Handles non-linearities and interactions exceptionally well
*   Handles imbalanced datasets better with scale_pos_weight
*   Is less sensitive to outliers than logistic regression
*   Due to regularization is less prone to overfitting than Random Forest

###6.3-Thresholds Optimization

To refine model selection beyond default classifier behavior, all three models were evaluated under optimal threshold tuning conditions. Two criteria were applied:


*   The threshold that maximizes the F1-score, and;
*   The optimal threshold that preserves the business requirement of achieving Recall ≥ 0.80.

Logistic Regression reached the recall target but required an aggressive reduction in the decision threshold, which significantly lowered precision and resulted in a weaker balance between false positives and false negatives. Random Forest could not achieve the required recall level without collapsing overall performance, confirming its unsuitability for our use case.
"""

import polars as pl
import numpy as np
from sklearn.metrics import (
    precision_recall_curve,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score,
)

print("Optimal Thresholds per Model (with Recall>=0.80 constraint)...")

threshold_results = []

TARGET_RECALL = 0.80

y_test_np = (
    y_test.to_numpy()
    if hasattr(y_test, "to_numpy")
    else (y_test.to_pandas().to_numpy() if hasattr(y_test, "to_pandas") else y_test)
)

for model_name in models.keys():
    y_prob = probabilities[model_name]

    if hasattr(y_prob, "to_numpy"):
        y_prob_np = y_prob.to_numpy()
    else:
        y_prob_np = np.array(y_prob)

    prec, rec, thr = precision_recall_curve(y_test_np, y_prob_np)

    prec_t = prec[:-1]
    rec_t  = rec[:-1]
    thr_t  = thr

    f1_t = 2 * (prec_t * rec_t) / (prec_t + rec_t + 1e-12)

    #Best F1 overall
    best_f1_idx = f1_t.argmax()
    best_f1_thr = thr_t[best_f1_idx]

    y_pred_f1 = (y_prob_np >= best_f1_thr).astype(int)
    acc_f1 = (y_pred_f1 == y_test_np).mean()
    prec_f1 = precision_score(y_test_np, y_pred_f1)
    rec_f1  = recall_score(y_test_np, y_pred_f1)
    f1_best = f1_score(y_test_np, y_pred_f1)
    roc_auc = roc_auc_score(y_test_np, y_prob_np)

    #Best threshold with Recall >= TARGET_RECALL
    mask = rec_t >= TARGET_RECALL
    if mask.any():
        idx_c = np.argmax(f1_t[mask])
        best_c_thr = thr_t[mask][idx_c]
    else:
        max_rec_idx = rec_t.argmax()
        best_c_thr = thr_t[max_rec_idx]

    y_pred_c = (y_prob_np >= best_c_thr).astype(int)
    acc_c = (y_pred_c == y_test_np).mean()
    prec_c = precision_score(y_test_np, y_pred_c)
    rec_c  = recall_score(y_test_np, y_pred_c)
    f1_c   = f1_score(y_test_np, y_pred_c)

    print(f"\n{model_name}:")
    print(
        f"  - Best-F1 threshold: {best_f1_thr:.3f} | "
        f"Acc {acc_f1:.4f} | Prec {prec_f1:.4f} | Recall {rec_f1:.4f} | "
        f"F1 {f1_best:.4f} | ROC-AUC {roc_auc:.4f}"
    )
    print(
        f"  - Best threshold with Recall≥{TARGET_RECALL:.2f}: {best_c_thr:.3f} | "
        f"Acc {acc_c:.4f} | Prec {prec_c:.4f} | Recall {rec_c:.4f} | F1 {f1_c:.4f}"
    )

    threshold_results.append({
        "Model": model_name,
        "ROC_AUC": roc_auc,
        "Best_F1_Threshold": best_f1_thr,
        "Best_F1_Accuracy": acc_f1,
        "Best_F1_Precision": prec_f1,
        "Best_F1_Recall": rec_f1,
        "Best_F1_F1": f1_best,
        f"Best_Threshold_Recall>={TARGET_RECALL:.2f}": best_c_thr,
        f"Acc_Recall>={TARGET_RECALL:.2f}": acc_c,
        f"Prec_Recall>={TARGET_RECALL:.2f}": prec_c,
        f"Recall_Recall>={TARGET_RECALL:.2f}": rec_c,
        f"F1_Recall>={TARGET_RECALL:.2f}": f1_c,
    })

save_file = output_path + "/model_thresholds_metrics.csv"
threshold_df = pl.DataFrame(threshold_results)
threshold_df.write_csv(save_file)
print(f"\nThreshold tuning results saved: {save_file}")

import numpy as np
import polars as pl
from sklearn.metrics import (
    precision_recall_curve,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score
)

print("\nThresholds Optimized for Recall ≥ 0.80 with Highest F1...\n")

target_recall = 0.80
recall_optimized_results = []

#Ensure y_test is numpy for sklearn
if hasattr(y_test, "to_numpy"):
    y_test_np = y_test.to_numpy()
elif hasattr(y_test, "to_pandas"):
    y_test_np = y_test.to_pandas().to_numpy()
else:
    y_test_np = np.asarray(y_test)

for model_name in models.keys():
    y_prob = probabilities[model_name]

    # --- Ensure y_prob is numpy ---
    if hasattr(y_prob, "to_numpy"):          # pandas/np-like
        y_prob_np = y_prob.to_numpy()
    elif hasattr(y_prob, "to_pandas"):       # polars
        y_prob_np = y_prob.to_pandas().to_numpy()
    else:
        y_prob_np = np.asarray(y_prob)

    # --- Precision, recall, thresholds ---
    prec, rec, thr = precision_recall_curve(y_test_np, y_prob_np)
    # Align with thresholds array length (n_thresholds = n_points - 1)
    prec_t, rec_t, thr_t = prec[:-1], rec[:-1], thr
    f1_t = 2 * (prec_t * rec_t) / (prec_t + rec_t + 1e-12)

    # --- Filter thresholds that achieve recall >= target_recall ---
    valid_idx = np.where(rec_t >= target_recall)[0]
    if len(valid_idx) == 0:
        print(f"\n{model_name}: No threshold reaches recall ≥ {target_recall:.2f}")
        continue

    # --- Choose threshold among those that maximizes F1 ---
    best_idx = valid_idx[np.argmax(f1_t[valid_idx])]
    best_thresh = thr_t[best_idx]

    # --- Predictions at best threshold ---
    y_pred_opt = (y_prob_np >= best_thresh).astype(int)

    accuracy = (y_pred_opt == y_test_np).mean()
    precision = precision_score(y_test_np, y_pred_opt)
    recall = recall_score(y_test_np, y_pred_opt)
    f1 = f1_score(y_test_np, y_pred_opt)
    roc_auc = roc_auc_score(y_test_np, y_prob_np)

    print(f"\n{model_name}:")
    print(f"  - Optimal Threshold (Recall≥{target_recall:.2f}, Max F1): {best_thresh:.3f}")
    print(f"  - Accuracy:  {accuracy:.4f}")
    print(f"  - Precision: {precision:.4f}")
    print(f"  - Recall:    {recall:.4f}")
    print(f"  - F1-Score:  {f1:.4f}")
    print(f"  - ROC-AUC:   {roc_auc:.4f}")

    recall_optimized_results.append({
        "Model": model_name,
        "Optimal_Threshold": float(best_thresh),
        "Accuracy": float(accuracy),
        "Precision": float(precision),
        "Recall": float(recall),
        "F1_Score": float(f1),
        "ROC_AUC": float(roc_auc)
    })


save_file = output_path + "/model_recall_optimized.csv"

if len(recall_optimized_results) == 0:
    print("\nNo model achieved the recall target; CSV not created.")
else:
    recall_opt_df = pl.DataFrame(recall_optimized_results)
    recall_opt_df.write_csv(save_file)
    print(f"\nThreshold tuning results saved: {save_file}")

"""###6.4-Confusion Matrices

Examining the confusion matrices for the three models (Logistic Regression, Random Forest, and XGBoost) provides a clearer understanding of the business impact of using each model.

Each matrix has four quadrants.

  *   **True Negatives (Top-left):** Customers correctly predicted as non-churners.No retention action needs to be taken, and this is the appropriate decision.  

  *   **False Positives (Top-right):** Customers predicted as churners but who would actually stay. The company will unnecessarily contact or offer an incentive to these customers, generating extra retention cost but not revenue loss.  

  *   **False Negatives (Bottom-left):** Customers who actually churn but were predicted as non-churners.These are the most critical errors: the company does not intervene and loses the customer's future revenue.  

  *   **True Positives (Bottom-right):** Customers correctly identified as churners. These are the customers who can be targeted with retention actions, where the intervention has the potential to generate positive ROI.

From a business perspective, the model should **minimise False Negatives**  (missed churners) while **keeping False Positives** (unnecessary actions) at an acceptable level, given the cost of campaigns.

*XGBoost's confusion matrix demonstrates strong coverage of true churners (high TP) with moderate and manageable FP, it offers the best compromise between revenue protection and retention cost. This makes XGBoost the most attractive option from a business standpoint, not only statistically but also in terms of how retention actions will be deployed in practice.*

"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

# Fixed order so the plots are always in the same sequence
model_order = ["Logistic Regression", "Random Forest", "XGBoost"]

# Colour map per model
model_cmaps = {
    "Logistic Regression": "Blues",
    "Random Forest": "Greens",
    "XGBoost": "Oranges"
}

y_test_np = y_test.to_numpy() if isinstance(y_test, pl.Series) else y_test

fig, axes = plt.subplots(1, 3, figsize=(20, 5))

for idx, model_name in enumerate(model_order):
    ax = axes[idx]
    preds = predictions[model_name]
    y_pred_np = preds.to_numpy() if isinstance(preds, pl.Series) else preds

    # Confusion matrix + percentages
    cm = confusion_matrix(y_test_np, y_pred_np)
    cm_percent = cm / cm.sum() * 100

    # Metrics
    prec = precision_score(y_test_np, y_pred_np)
    rec = recall_score(y_test_np, y_pred_np)
    f1 = f1_score(y_test_np, y_pred_np)

    cmap = model_cmaps.get(model_name, "Blues")

    # Draw heatmap and capture mappable (QuadMesh) to access cmap + norm
    ax = sns.heatmap(
        cm,
        annot=False,
        fmt="d",
        cmap=cmap,
        cbar=False,
        xticklabels=["Pred: No Churn", "Pred: Churn"],
        yticklabels=["Actual: No Churn", "Actual: Churn"],
        ax=axes[idx]
    )

    mappable = ax.collections[0]   # QuadMesh
    norm = mappable.norm
    cmap_obj = mappable.cmap

    # Annotate with counts and percentages, adapting text colour to background
    for i in range(2):
        for j in range(2):
            count = cm[i, j]
            pct = cm_percent[i, j]

            # Background colour for this cell after colormap
            r, g, b, _ = cmap_obj(norm(count))
            # Perceived brightness (0 = dark, 1 = bright)
            brightness = 0.299 * r + 0.587 * g + 0.114 * b

            text_color = "white" if brightness < 0.55 else "black"

            ax.text(
                j + 0.5,
                i + 0.5,
                f"{count}\n({pct:.1f}%)",
                ha="center",
                va="center",
                fontsize=12,
                fontweight="bold",
                color=text_color
            )

    ax.set_title(model_name, fontsize=14, fontweight="bold", pad=10)
    ax.set_xlabel(
        f"Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1:.3f}",
        fontsize=11,
        labelpad=10
    )
    ax.set_ylabel("")

# Common y-label on the left side only
axes[0].set_ylabel("Actual", fontsize=12)

plt.suptitle("Confusion Matrices – Model Comparison",
             fontsize=16, fontweight="bold", y=1.05)
plt.tight_layout()

panel_path = output_path + "confusion_matrices_panel.png"
fig.savefig(panel_path, dpi=300, bbox_inches="tight")
plt.show()
plt.close(fig)

print(f"Confusion matrix panel saved to: {panel_path}")

"""###6.5-ROC Curves"""

plt.figure(figsize=(10, 8))

# Convert y_test to numpy if stored as Polars
y_test_np = y_test.to_numpy() if isinstance(y_test, pl.Series) else y_test

for model_name, probs in probabilities.items():
    # Convert probabilities to numpy if Polars
    y_prob_np = probs.to_numpy() if isinstance(probs, pl.Series) else probs

    # Compute ROC components
    fpr, tpr, _ = roc_curve(y_test_np, y_prob_np)
    auc = roc_auc_score(y_test_np, y_prob_np)

    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {auc:.3f})", linewidth=2)

# Baseline diagonal
plt.plot([0, 1], [0, 1], "k--", label="Random Classifier", linewidth=1)

plt.xlabel("False Positive Rate", fontsize=10)
plt.ylabel("True Positive Rate (Recall)", fontsize=10)
plt.title("ROC Curves - Model Comparison", fontsize=12, fontweight="bold")
plt.legend(loc="lower right", fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()

plt.savefig(output_path + "roc_curves_comparison.png", dpi=300, bbox_inches="tight")
plt.show()
plt.close()

print(f"ROC curves saved: {output_path}roc_curves_comparison.png")

"""###6.6-Best Model Decision"""

#Random Forest feature importance
rf_importance = pl.DataFrame({
    "Feature": X.columns,
    "Importance": models["Random Forest"].feature_importances_.tolist()
}).sort("Importance", descending=True)

rf_importance.write_csv(output_path + "feature_importance_rf.csv")
print("Random Forest feature importance saved")

#XGBoost feature importance
xgb_importance = pl.DataFrame({
    "Feature": X.columns,
    "Importance": models["XGBoost"].feature_importances_.tolist()
}).sort("Importance", descending=True)

xgb_importance.write_csv(output_path + "feature_importance_xgb.csv")
print("XGBoost feature importance saved")

#Visualization of Top 15 Features
fig, axes = plt.subplots(1, 2, figsize=(16, 8))

#Convert to pandas for Matplotlib plotting convenience
rf_pd = rf_importance.head(15).to_pandas()
xgb_pd = xgb_importance.head(15).to_pandas()

#Random Forest
axes[0].barh(rf_pd["Feature"], rf_pd["Importance"], color="#4CAF50", edgecolor="black")
axes[0].set_xlabel("Importance", fontsize=10)
axes[0].set_title("Top 15 Features - Random Forest", fontsize=12, fontweight="bold")
axes[0].invert_yaxis()

#XGBoost
axes[1].barh(xgb_pd["Feature"], xgb_pd["Importance"], color="#2196F3", edgecolor="black")
axes[1].set_xlabel("Importance", fontsize=10)
axes[1].set_title("Top 15 Features - XGBoost", fontsize=12, fontweight="bold")
axes[1].invert_yaxis()

plt.tight_layout()
plt.savefig(output_path + "feature_importance_comparison.png", dpi=300, bbox_inches="tight")
plt.show()
plt.close()
print("Feature importance visualization saved")

"""Comparing the top 15 features for Random Forest and XGBoost, it became evident that **XGBoost's feature importance distribution** showed an excessive reliance on a single variable (Contract_Value). Such concentration increases the risk of instability and limits the model's ability to capture the broader drivers of churn.

To **ensure greater stability, interpretability, and robustness when generalising to new customers, we selected the Random Forest model**. Its more balanced distribution of importances and greater consistency in the feature ranking provide a stronger foundation for operational deployment.

Furthermore, Random Forest enables a richer and more actionable business interpretation, which is essential for designing effective and targeted retention strategies.

Our decision was supported also in metrics comparison:  



| Modelo                  | Accuracy | Precision | Recall     | F1     | ROC-AUC |
| ----------------------- | -------- | --------- | ---------- | ------ | ------- |
| **Logistic Regression** | 0.8190   | 0.6227    | **0.8875** | 0.7401 | 0.9046  |
| **Random Forest**       | 0.8162   | 0.6106    | **0.8281** | 0.6985 | 0.9025  |
| **XGBoost**             | 0.8382   | 0.6392    | **0.8102** | 0.7146 | 0.9106  |

   
  
Although **XGBoost shows slight metric improvements**, these differences are only marginally significant and do not provide enough practical benefit to justify the lower stability in feature importance. **Random Forest offers greater robustness**, interpretability, and stability in the distribution of features, making it more suitable for operational use and for generating predictions for new customers.  


In the context of churn prediction, **Recall is the most critical evaluation** metric because it measures the model's ability to correctly identify customers who are genuinely at risk of leaving. Missing a churner (a false negative) usually carries a much higher business cost than incorrectly flagging a loyal customer as high-risk. For this reason, **a model with more balanced feature behaviour and strong Recall performance—such as Random Forest—is better aligned with the operational objective of prioritising timely and effective retention actions.**

#7-Best Model Details

##7.1-Feature Importance
"""

import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import pandas as pd

# Set visualization style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("Feature Importance Analysis")
best_RF_model = models["Random Forest"]

# Extract feature importance from best RF model
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': best_RF_model.feature_importances_
}).sort_values('importance', ascending=False)

# Display top 15 features
print("\nTop 15 Most Important Features:")
print(feature_importance.head(15))

# Visualize feature importance
fig, ax = plt.subplots(figsize=(12, 8))
top_features = feature_importance.head(15)
sns.barplot(data=top_features, y='feature', x='importance', palette='viridis', ax=ax)
ax.set_title('Top 15 Feature Importance (RF)', fontsize=16, fontweight='bold')
ax.set_xlabel('Importance Score', fontsize=10)
ax.set_ylabel('Feature', fontsize=10)
plt.tight_layout()
plt.savefig(output_path + '/feature_importance_RandomForest.png', dpi=300, bbox_inches='tight')
plt.show()

"""##7.2-F. Importance By Category"""

def categorize_feature(feature_name):
    """Categorize features into business-relevant groups"""
    fl = feature_name.lower()

    if any(t in fl for t in ['tenure', 'month', 'age']):
        return 'Temporal / Lifecycle'
    elif any(t in fl for t in ['cltv', 'revenue', 'charge', 'refund', 'total']):
        return 'Financial'
    elif any(t in fl for t in ['contract', 'paperless', 'payment']):
        return 'Contractual'
    elif any(t in fl for t in ['internet', 'phone', 'streaming', 'security',
                               'backup', 'support', 'protection']):
        return 'Services'
    elif any(t in fl for t in ['city', 'population']):
        return 'Geographic'
    elif any(t in fl for t in ['gender', 'senior', 'married', 'dependents']):
        return 'Demographic'
    elif any(t in fl for t in ['satisfaction', 'score']):
        return 'Satisfaction'
    return 'Other'

# Categorizar features
feature_importance['Category'] = feature_importance['feature'].apply(categorize_feature)

# Ordenado do maior para o menor
category_importance = (
    feature_importance.groupby('Category')['importance']
    .sum()
    .sort_values(ascending=False)
)

category_importance_fmt = category_importance.apply(lambda v: f"{v:.4f}")

print("\nFeature Importance by Category (Aggregated):\n")
print(category_importance_fmt)

category_importance_sorted = category_importance.sort_values(ascending=True)

fig, ax = plt.subplots(figsize=(10, 6))

bars = ax.barh(
    category_importance_sorted.index,
    category_importance_sorted.values,
    color="#457B9D",
    edgecolor="black",
    alpha=0.9
)

ax.set_title("Feature Importance by Category", fontsize=16, fontweight="bold", pad=12)
ax.set_xlabel("Total Importance Score", fontsize=12, weight="bold")
ax.set_ylabel("Category", fontsize=12, weight="bold")

ax.grid(axis="x", linestyle="--", alpha=0.4)

# Add value labels
for bar, value in zip(bars, category_importance_sorted.values):
    ax.text(
        value + (value * 0.01),
        bar.get_y() + bar.get_height() / 2,
        f"{value:.3f}",
        va="center",
        fontsize=9,
        fontweight='bold'
    )

plt.tight_layout()
plt.savefig(output_path + "/feature_importance_by_category.png", dpi=300, bbox_inches='tight')
plt.show()

"""Categories:

Temporal/Lifecycle (tenure', 'month', 'age')  
Contratual ('contract', 'paperless', 'payment')  
Geographic ('city', 'population')  
Finantial ('cltv', 'revenue', 'charge', 'refund', 'total')  
Services ('internet', 'phone', 'streaming', 'security', 'backup', 'support', 'protection')  
Demographic ('gender', 'senior', 'married', 'dependents')
Other ()

Both, Feature Importance and Feature Importance by Category highlights which variables most strongly influence churn predictions.

Random Forest feature importance is based on impurity reduction across the decision trees. Higher values indicate variables that consistently help the model separate churners from
non-churners.

Understanding the drivers of churn is as important as prediction accuracy. Feature importance enables the business to:

- validate domain assumptions,
- identify actionable levers (e.g., contract type, monthly charge),
- design targeted retention strategies.

The top features reveal the structural mechanisms behind churn (e.g. contract duration, service complexity, payment behaviour), providing a strong foundation for precise, economically informed retention actions.

##7.3-Confusion Matrix Heatmap
"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Compute confusion matrix
y_pred_RF = best_RF_model.predict(X_test)
cm = confusion_matrix(y_test, y_pred_RF)

# Extract TN, FP, FN, TP
tn, fp, fn, tp = cm.ravel()

# Percentages by row (actual class)
cm_percent = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis] * 100

cell_text = np.array([
    [f"TN\n{tn}\n({cm_percent[0,0]:.1f}%)",
     f"FP\n{fp}\n({cm_percent[0,1]:.1f}%)"],
    [f"FN\n{fn}\n({cm_percent[1,0]:.1f}%)",
     f"TP\n{tp}\n({cm_percent[1,1]:.1f}%)"]
])

plt.figure(figsize=(9, 7))

ax = sns.heatmap(
    cm,
    annot=False,
    fmt='',
    cmap='Blues',
    cbar=False,
    linewidths=1.5,
    linecolor='white'
)

for i in range(2):
    for j in range(2):
        text = cell_text[i, j]

        if (i, j) in [(0, 0), (1, 1)]:
            color = "white"
        else:
            color = "darkred"

        ax.text(
            j + 0.5,
            i + 0.5,
            text,
            ha='center',
            va='center',
            fontsize=14,
            fontweight='bold',
            color=color
        )

plt.title("Confusion Matrix – Random Forest Model", fontsize=18, weight='bold', pad=20)
plt.xlabel("Predicted Class", fontsize=10, weight='bold')
plt.ylabel("Actual Class", fontsize=10, weight='bold')

plt.xticks(
    ticks=[0.5, 1.5],
    labels=["Stayed", "Churned"],
    fontsize=12
)
plt.yticks(
    ticks=[0.5, 1.5],
    labels=["Stayed", "Churned"],
    fontsize=12,
    rotation=0
)

plt.tight_layout()
plt.savefig(output_path + "/confusion_matrix_RF.png", dpi=300, bbox_inches='tight')
plt.show()

"""The confusion matrix illustrates how the Random Forest model performs in terms of
correct vs. incorrect classifications for both churn and non-churn customers.

- **True Negatives (TN):** loyal customers correctly identified.
- **True Positives (TP):** churners successfully detected — this is where value is created.
- **False Negatives (FN):** churners missed by the model — the most costly type of error.
- **False Positives (FP):** loyal customers wrongly flagged as churners — these increase retention cost.

By inspecting the balance between TP and FN, we understand whether the chosen threshold and feature set allow the model to detect churners reliably.

The model generates a healthy TP count while keeping FN under control, confirming that the Random Forest is capturing meaningful churn patterns rather than overfitting noise.

**TN = 966 (93.3%)** These are customers who did not churn and were correctly identified as “Stayed”. The very high percentage (93.3%) shows that the model is extremely reliable at recognising loyal customers.

From a cost-efficiency standpoint, this reduces false alarms and avoids unnecessary retention actions.

**FP = 69 (6.7%)** These are customers who actually stayed, but the model incorrectly predicted as “Churned”. False positives increase retention cost: interventions are applied to customers who didn't need them.

A 6.7% FP rate is acceptably low — the model does not over-trigger alerts.

**FN = 152 (40.6%)** These are real churners whom the model failed to detect. These are the most costly errors for the business, because the company loses customers without any action taken.

A rate of ~41% may sound high, but churn prediction is inherently difficult due to minority-class imbalance (and this performance is aligned with market benchmarks).

This is where threshold tuning and cost-sensitive optimisation can further improve recall.

**TP = 222 (59.4%)** These are customers who churned and were correctly identified. The model detects almost 60% of all churners — a meaningful and actionable percentage.

This enables targeted retention campaigns before customers leave.

**Overall**
- The model is **very strong at detecting non-churners** (high TN, low FP), reducing unnecessary retention spend.
- It identifies a **meaningful proportion of churners** (TP ~59%), providing actionable
  insight for customer retention teams.
- **Recall for churn** can be improved (FN ~41%) if the business wants a more aggressive   churn-detection strategy.

##7.4-ROC Curve
"""

plt.figure(figsize=(10, 8))

y_test_np = y_test.to_numpy() if isinstance(y_test, pl.Series) else y_test

#Select Random Forest model
rf_probs = probabilities["Random Forest"]
rf_probs_np = rf_probs.to_numpy() if isinstance(rf_probs, pl.Series) else rf_probs

# Compute ROC components
fpr, tpr, _ = roc_curve(y_test_np, rf_probs_np)
roc_auc_rf = roc_auc_score(y_test_np, rf_probs_np)

# Plot ROC curve
plt.plot(fpr, tpr, label=f"Random Forest (AUC = {roc_auc_rf:.3f})",
         linewidth=2, color="blue")

#Diagonal line
plt.plot([0, 1], [0, 1], "k--", label="Random Classifier", linewidth=1)

plt.xlabel("False Positive Rate", fontsize=10)
plt.ylabel("True Positive Rate (Recall)", fontsize=10)
plt.title("ROC Curve - Random Forest", fontsize=12, fontweight="bold")
plt.legend(loc="lower right", fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()

plt.savefig(output_path + "roc_curve_random_forest.png", dpi=300, bbox_inches="tight")
plt.show()
plt.close()

print(f"ROC curve saved: {output_path}roc_curve_random_forest.png")

"""The ROC curve plots the True Positive Rate against the False Positive Rate across all possible classification thresholds. The **AUC** (area under the curve) summarises the model's overall discriminative ability.

A curve bending strongly toward the upper-left corner indicates high separability. AUC > 0.90 is considered excellent.

Churn prediction requires not only detecting churners but also understanding how performance evolves as the business tunes the decision threshold.

The Random Forest shows a high-quality ROC profile, revealing that the model consistently assigns higher probabilities to churners than to non-churners — a sign of strong generalisation.

##7.5-Precision Recall Curve
"""

from sklearn.metrics import precision_recall_curve, average_precision_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import polars as pl
import numpy as np

# --- Garantir y_test em numpy ---
y_test_np = y_test.to_numpy() if isinstance(y_test, pl.Series) else np.asarray(y_test)

# --- Probabilidades do Random Forest ---
rf_probs = probabilities["Random Forest"]
rf_probs_np = rf_probs.to_numpy() if isinstance(rf_probs, pl.Series) else np.asarray(rf_probs)

# --- Precision–Recall curve ---
prec, rec, thr = precision_recall_curve(y_test_np, rf_probs_np)
auc_pr = average_precision_score(y_test_np, rf_probs_np)

# Alinhar com o array de thresholds:
# thr tem length = n_points - 1 → vamos usar prec[:-1], rec[:-1]
prec_t = prec[:-1]
rec_t  = rec[:-1]
thr_t  = thr

# --- F1 para cada threshold ---
f1_t = 2 * (prec_t * rec_t) / (prec_t + rec_t + 1e-12)

best_idx = f1_t.argmax()
best_thr = float(thr_t[best_idx])
best_prec = float(prec_t[best_idx])
best_rec  = float(rec_t[best_idx])
best_f1   = float(f1_t[best_idx])

print("\nOptimal threshold for Random Forest (by F1 on PR curve):")
print(f"  Threshold: {best_thr:.4f}")
print(f"  Precision: {best_prec:.4f}")
print(f"  Recall:    {best_rec:.4f}")
print(f"  F1-score:  {best_f1:.4f}")

# --- Plot PR curve ---
plt.figure(figsize=(10, 8))

plt.plot(rec, prec, linewidth=2,
         label=f"Random Forest (AP = {auc_pr:.3f})")

# Marcar o ponto do threshold ótimo
plt.scatter(best_rec, best_prec,
            s=80, edgecolor="black", facecolor="red",
            zorder=5,
            label=f"Best F1 point\n(thr={best_thr:.3f})")

# Baseline (taxa de positivos)
baseline = y_test_np.mean()
plt.hlines(baseline, xmin=0, xmax=1, colors='k', linestyles='--',
           label=f"Baseline (Positive Rate = {baseline:.3f})")

plt.xlabel("Recall", fontsize=10)
plt.ylabel("Precision", fontsize=10)
plt.title("Precision–Recall Curve - Random Forest", fontsize=12, fontweight="bold")
plt.legend(loc="lower left", fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()

plt.savefig(output_path + "precision_recall_random_forest_bestF1.png",
            dpi=300, bbox_inches="tight")
plt.show()
plt.close()

print(f"Precision–Recall curve saved: {output_path}precision_recall_random_forest_bestF1.png")

"""In imbalanced datasets, the Precision–Recall curve is often more revealing than ROC. It helps us understand the trade-off between detecting churners (recall) and avoiding false alarms (precision).

A curve above the baseline indicates strong minority-class performance. Steeper curves demonstrate reliable churn discrimination.

For churn, high recall is essential, but precision cannot drop too much — otherwise retention campaigns become unnecessarily expensive.

The Random Forest maintains a favourable balance between precision and recall across a wide range of thresholds, confirming that it can support scenario-based decision rules.

**Conclusions**

These two plots provide a complete picture of how well the model distinguishes churners from on-churners, especially in an imbalanced dataset.

The ROC curve plots the **True Positive Rate (recall)** against the **False Positive Rate**, showing how the model behaves as the decision threshold shifts.

- The curve clearly bends toward the upper-left corner, indicating strong discriminative ability. The **AUC of 0.902** confirms that the model is able to correctly rank churners above non-churners in ~90% of all random customer pairs, which is far better than a random classifier.

The ROC curve assesses overall separability. A high AUC means the model consistently assigns higher churn probabilities to true churners, regardless of the threshold.

The Precision-Recall (PR) curve focuses specifically on the model's behaviour on the **churn class**, which is the minority group.

- Precision starts high and declines gradually as recall increases, illustrating a predictable trade-off. The **Average Precision (AP = 0.756)** is strong for a churn dataset, reflecting stability in minority-class detection.
- The red point marks the **best F1-score** (threshold ≈ 0.35), where the balance between precision and recall is optimal for this dataset.
- The horizontal line shows the **baseline** (positive class prevalence of 26.5%). The model performs far above this reference across the entire curve.

- **ROC AUC = 0.902** → The model has excellent general discriminative power.  
- **PR AP = 0.756** → The model performs strongly where it matters most: identifying churners in an imbalanced setting.
- **The F1-optimal threshold (~0.35)** offers a good operational trade-off between:
  1) detecting enough churners (high recall),
  2) and avoiding excessive false positives (maintaining precision).

The Random Forest is a robust churn-prediction model: it not only separates churners from non-churners effectively (ROC), but also maintains strong reliability on the minority class (PR). **This combination makes it suitable for real-world retention strategies, where both accuracy and cost-efficiency matter.**

##7.6-Risk Score Calculation
"""

#Work on a Pandas copy for scoring & risk analysis
# df_scored is the dataframe to store risk score of each customer

df_scored = df_model.to_pandas().copy()

#Calculate churn probability for all customers
df_scored['Churn_Probability'] = best_RF_model.predict_proba(
    df_scored[X_train.columns]
)[:, 1]

#Create risk categories based on Churn_Probability
df_scored['Risk_Category'] = pd.cut(
    df_scored['Churn_Probability'],
    bins=[-0.01, 0.3, 0.6, 1.01],
    labels=['Low Risk', 'Medium Risk', 'High Risk']
)

risk_counts = df_scored['Risk_Category'].value_counts().sort_index()
risk_pct = (risk_counts / len(df_scored) * 100).round(2)

risk_summary = (
    pd.DataFrame({
        'Risk_Category': risk_counts.index,
        'Customers': risk_counts.values,
        'Percentage': risk_pct.values
    })
    .sort_values('Risk_Category')
)

print("\nCustomer Risk Distribution:")
print(risk_summary.to_string(index=False))

risk_cltv = (
    df_scored
    .groupby('Risk_Category')['CLTV']
    .agg(['sum', 'mean'])
    .reset_index()
)

#Ensure consistent order Low → Medium → High
order = ['Low Risk', 'Medium Risk', 'High Risk']
risk_summary = risk_summary.set_index('Risk_Category').loc[order].reset_index()
risk_cltv = risk_cltv.set_index('Risk_Category').loc[order].reset_index()

print("\nCLTV at Risk by Category (summary):")
print(
    risk_cltv.assign(
        sum_m=lambda d: (d['sum'] / 1_000_000).round(2),
        mean_eur=lambda d: d['mean'].round(2)
    )[["Risk_Category", "sum_m", "mean_eur"]]
    .rename(columns={
        "sum_m": "Total_CLTV_M€",
        "mean_eur": "Avg_CLTV_€"
    })
    .to_string(index=False)
)

#Visualize risk distribution
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

color_map = {
    'Low Risk': '#2ecc71',
    'Medium Risk': '#f39c12',
    'High Risk': '#e74c3c'
}
bar_colors = [color_map[c] for c in risk_summary['Risk_Category']]

#1) Bar chart for risk distribution
ax1.bar(
    risk_summary['Risk_Category'],
    risk_summary['Percentage'],
    color=bar_colors,
    edgecolor='black'
)

ax1.set_title('Customer Risk Distribution', fontsize=14, fontweight='bold')
ax1.set_xlabel('Risk Category', fontsize=11)
ax1.set_ylabel('Customers (%)', fontsize=11)
ax1.grid(axis='y', linestyle='--', alpha=0.5)

# Add % labels
for i, row in risk_summary.iterrows():
    ax1.text(
        i,
        row['Percentage'] + 0.5,
        f"{row['Percentage']:.1f}%",
        ha='center',
        va='bottom',
        fontsize=9,
        fontweight='bold'
    )

#2) CLTV at risk by category
cltv_m = risk_cltv['sum'] / 1_000_000  # millions
ax2.bar(
    risk_cltv['Risk_Category'],
    cltv_m,
    color=bar_colors,
    edgecolor='black'
)

ax2.set_title('Total CLTV at Risk by Category', fontsize=14, fontweight='bold')
ax2.set_ylabel('CLTV (€ Millions)', fontsize=11)
ax2.set_xlabel('Risk Category', fontsize=11)
ax2.grid(axis='y', linestyle='--', alpha=0.5)

# Add value labels
for i, v in enumerate(cltv_m):
    ax2.text(
        i,
        v + max(cltv_m) * 0.01,
        f"€ {v:.2f}M",
        ha='center',
        va='bottom',
        fontsize=9,
        fontweight='bold'
    )

plt.tight_layout()
plt.savefig(output_path + '/customer_risk_profiling.png', dpi=300, bbox_inches='tight')
plt.show()

high_risk_cltv_m = float(
    risk_cltv.loc[risk_cltv['Risk_Category'] == 'High Risk', 'sum'] / 1_000_000
)

print(
    f"\nTotal CLTV at High Risk: €{high_risk_cltv_m:.2f}M"
)

bins = [-0.01, 0.3, 0.6, 1.01]

cp_bins = pd.cut(
    df_scored['Churn_Probability'],
    bins=bins,
    include_lowest=True
)

pd.crosstab(df_scored['Risk_Category'], cp_bins)

#display(df_scored)
#display(df_scored.info())
#display(df_scored.describe())

"""##7.7-High Risk Customer Profile"""

# Com base em df_scored copia os clientes de alto risco
high_risk_customers = df_scored[df_scored['Risk_Category'] == 'High Risk'].copy()

n_hr = len(high_risk_customers)
n_total = len(df_scored)
share_hr = n_hr / n_total * 100 if n_total > 0 else 0

print("\n" + "=" * 90)
print("HIGH-RISK CUSTOMER PROFILE ANALYSIS".center(90))
print("=" * 90)
print(f"High-Risk Customers: {n_hr:,} of {n_total:,} total "
      f"({share_hr:.1f}% of the active base)")
print("-" * 90)

#1. Contract Type
print("\n1-Contract Type Distribution")
print("-" * 90)

contract_dist = (
    high_risk_customers['Contract']
    .value_counts(normalize=True)
    .mul(100)
    .round(2)
)

if len(contract_dist) == 0:
    print("   No contract data available for high-risk customers.")
else:
    print("   Contract Type                 |   % of High-Risk Customers")
    print("   " + "-" * 60)
    for c, pct in contract_dist.items():
        print(f"   {c:<28} | {pct:>6.2f}%")

#2.Show Tenure in Months
print("\n2-Tenure (in Months)")
print("-" * 90)

t = high_risk_customers['Tenure in Months'].describe()

print(f"   Count:           {t['count']:.0f}")
print(f"   Mean:            {t['mean']:.2f} months")
print(f"   Median:          {t['50%']:.2f} months")
print(f"   Min – Max:       {t['min']:.0f} – {t['max']:.0f} months")
print(f"   Std Dev:         {t['std']:.2f} months")

#3.Payment Method
if 'Payment_Method' in high_risk_customers.columns:
    print("\n3-Payment Method Distribution")
    print("-" * 90)

    pm = (
        high_risk_customers['Payment_Method']
        .value_counts(normalize=True)
        .mul(100)
        .round(2)
    )

    if len(pm) == 0:
        print("   No payment method data available.")
    else:
        print("   Payment Method                |   % of High-Risk Customers")
        print("   " + "-" * 60)
        for method, pct in pm.items():
            print(f"   {method:<28} | {pct:>6.2f}%")

#4.Service Complexity
if 'Number_of_Services' in high_risk_customers.columns:
    print("\n.Service Complexity")
    print("-" * 90)

    avg_hr = high_risk_customers['Number_of_Services'].mean()
    avg_all = df_scored['Number_of_Services'].mean()

    print(f"   Avg No. of Services (High-Risk):   {avg_hr:.2f}")
    print(f"   Avg No. of Services (Overall):     {avg_all:.2f}")

#5.Demographic Profile
print("\n.Demographic Profile")
print("-" * 90)

senior_pct = (high_risk_customers['Senior Citizen_encoded'] == 1).mean() * 100
print(f"   Senior Citizens (encoded=1):  {senior_pct:.1f}%")

if 'Married' in high_risk_customers.columns:
    married_pct = (high_risk_customers['Married'] == 'Yes').mean() * 100
    print(f"   Married:                      {married_pct:.1f}%")

#6.Financial Metrics
print("\n6.Financial Metrics")
print("-" * 90)

avg_monthly = high_risk_customers['Monthly Charge'].mean()
avg_cltv = high_risk_customers['CLTV'].mean()

print(f"   Avg Monthly Charge (High-Risk):   €{avg_monthly:,.2f}")
print(f"   Avg CLTV (High-Risk):             €{avg_cltv:,.2f}")

print("\n" + "=" * 90 + "\n")

"""##7.8-Tenure Critical Period vs Churn"""

import pandas as pd
import matplotlib.pyplot as plt

# Garantir coluna numérica de churn (0/1)
if "Churn_Numeric" not in df_scored.columns:
    # 1 = churned, 0 = restante
    df_scored["Churn_Numeric"] = (df_scored["Customer Status"] == "Churned").astype(int)

# Criar bins de tenure (6 meses)
tenure_bins = list(range(0, 73, 6))  # 0-6, 6-12, ..., 66-72
df_scored["Tenure_Bin"] = pd.cut(
    df_scored["Tenure in Months"],
    bins=tenure_bins,
    labels=[f"{i}-{i+6}m" for i in tenure_bins[:-1]],
    right=False  # [0,6), [6,12), etc.
)

# Agregação: churn médio (taxa) e número de clientes por bin
tenure_analysis = (
    df_scored
    .groupby("Tenure_Bin", observed=True)
    .agg(
        Churn_Rate=("Churn_Numeric", "mean"),
        Customer_Count=("Churn_Numeric", "count")
    )
    .reset_index()
)

tenure_analysis["Churn_Rate"] = tenure_analysis["Churn_Rate"] * 100

# Remover bins vazios (se existirem)
tenure_analysis = tenure_analysis.dropna(subset=["Tenure_Bin"])

# Gráfico de 2 eixos
fig, ax1 = plt.subplots(figsize=(14, 6))

# Linha de churn
color_line = "tab:red"
ax1.set_xlabel("Tenure Period", fontsize=12)
ax1.set_ylabel("Churn Rate (%)", color=color_line, fontsize=12)
ax1.plot(
    tenure_analysis["Tenure_Bin"].astype(str),
    tenure_analysis["Churn_Rate"],
    color=color_line,
    marker="o",
    linewidth=2,
    markersize=8,
    label="Churn Rate"
)
ax1.tick_params(axis="y", labelcolor=color_line)
ax1.grid(True, alpha=0.3)

# Destacar período crítico (primeiro bin, 0-6m)
ax1.axvspan(-0.5, 0.5, alpha=0.2, color="red", label="Critical Period (0–6m)")

# Barras com número de clientes
ax2 = ax1.twinx()
color_bar = "tab:blue"
ax2.set_ylabel("Number of Customers", color=color_bar, fontsize=12)
ax2.bar(
    tenure_analysis["Tenure_Bin"].astype(str),
    tenure_analysis["Customer_Count"],
    alpha=0.3,
    color=color_bar,
    label="Customer Count"
)
ax2.tick_params(axis="y", labelcolor=color_bar)

plt.title(
    "Churn Rate by Tenure Period - Critical Period Analysis (Q4)",
    fontsize=16,
    fontweight="bold",
    pad=20
)
plt.xticks(rotation=45, ha="right")

# Legenda combinada (linha + barras + highlight)
lines1, labels1 = ax1.get_legend_handles_labels()
lines2, labels2 = ax2.get_legend_handles_labels()
ax1.legend(lines1 + lines2, labels1 + labels2, loc="upper right")

plt.tight_layout()
plt.savefig(output_path + "/tenure_critical_period_q4.png", dpi=300, bbox_inches="tight")
plt.show()

print("\nTenure critical period visualization created (Q4)")

"""The chart highlights how churn behaviour evolves across different tenure segments and identifies the *critical risk window* where customers are significantly more likely to leave. The analysis combines two perspectives:

- **Churn Rate** (red line) — the proportion of customers who churn within each tenure band.
- **Customer Count** (blue bars) — the number of customers currently in each tenure segment.

The churn rate peaks sharply in the **0–6 month** segment, exceeding **50%**, and represents the highest risk of customer loss.
This early-period churn indicates that customers struggle during the onboarding and early-value phases.  

This should be one of the **primary intervention zone**, where proactive actions (onboarding, service support, early feedback cycles) can deliver the largest impact.

Early churn is typically driven by unmet expectations, billing confusion, service friction, or poor setup experiences. Addressing this segment generates the greatest ROI because preventing churn early preserves long-term customer lifetime value.

After the initial peak, churn gradually decreases as tenure increases:  

  - **6-12m:** churn stabilises around ~36%
  - **12-18m and 18-24m:** further declines
  - Beyond **30 months**, churn consistently falls below **25%**
  - Customers with **>48 months** tenure show very low churn probability (<15%)

The longer customers stay, the more loyal they become.
Higher tenure often correlates with:
- deeper product familiarity,
- smoother billing cycles,
- reduced switching incentives,
- increased perceived value.

The bars show that some mid-tenure groups have large customer volumes. Even if their churn rates are not the highest, these segments represent significant revenue risk due to their size.

Targeted retention programs should therefore focus on:
  - early-life customers (high churn risk),
  - large-volume mid-tenure segments (high revenue at risk).

##7.9-CLTV vs. Churn
"""

import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Create CLTV segments (quintiles, can adjust q)
df_scored_seg = df_scored.copy()
df_scored_seg['CLTV_Segment'] = pd.qcut(
    df_scored_seg['CLTV'],
    q=5,
    labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']
)

# Aggregate by CLTV segment
cltv_seg_summary = (
    df_scored_seg
    .groupby('CLTV_Segment')
    .agg(
        Avg_Churn_Prob=('Churn_Probability', 'mean'),
        Total_CLTV=('CLTV', 'sum'),
        Customers=('CLTV', 'count')
    )
    .reset_index()
)

# Convert CLTV to millions for easier reading
cltv_seg_summary['Total_CLTV_M'] = cltv_seg_summary['Total_CLTV'] / 1_000_000

# --- Build combined bar + line chart ---
fig = make_subplots(
    rows=1,
    cols=1,
    specs=[[{"secondary_y": True}]],
    subplot_titles=["CLTV Segment vs Average Churn Probability & Total CLTV (Q6)"]
)

# Bar: Total CLTV (M€) by segment
fig.add_trace(
    go.Bar(
        x=cltv_seg_summary['CLTV_Segment'],
        y=cltv_seg_summary['Total_CLTV_M'],
        name='Total CLTV (M€)',
        marker_color='#457B9D',
        text=[f"{v:.2f}M" for v in cltv_seg_summary['Total_CLTV_M']],
        textposition='outside'
    ),
    row=1,
    col=1,
    secondary_y=False
)

# Line: Avg churn probability by segment
fig.add_trace(
    go.Scatter(
        x=cltv_seg_summary['CLTV_Segment'],
        y=cltv_seg_summary['Avg_Churn_Prob'] * 100,  # in %
        name='Avg Churn Probability (%)',
        mode='lines+markers+text',
        marker=dict(size=9, color='#E63946'),
        line=dict(width=2),
        text=[f"{v*100:.1f}%" for v in cltv_seg_summary['Avg_Churn_Prob']],
        textposition='top center'
    ),
    row=1,
    col=1,
    secondary_y=True
)

# Layout & axes
fig.update_layout(
    #title_text="Customer Lifetime Value Segments vs Churn Probability (Q6)",
    #title_font_size=18,
    height=600,
    width=950,
    legend=dict(orientation='h', yanchor='bottom', y=-0.2, xanchor='center', x=0.5),
    margin=dict(l=70, r=40, t=80, b=80),
)

fig.update_xaxes(
    title_text="CLTV Segment",
    tickangle=0
)

fig.update_yaxes(
    title_text="Total CLTV (M€)",
    secondary_y=False
)

fig.update_yaxes(
    title_text="Average Churn Probability (%)",
    secondary_y=True,
    rangemode='tozero'
)

fig.write_html(output_path + '/cltv_vs_churn_probability.html')
fig.show()

print("\nSegmented CLTV vs Churn Probability visualization created")

"""The chart combines two key dimensions — **Customer Lifetime Value (CLTV)** and **churn probability**, to identify which customer segments contribute the most revenue and which are at highest risk of leaving. The bars - **Total CLTV (€M)** per segment, showing the economic weight of each group, and the line **Average predicted churn probability (%)** per segment, showing behavioural risk.

The line shows a clear downward trend: **Very Low CLTV** customers exhibit the highest churn probability (**33.9%**); As CLTV increases (Low → Medium → High), average churn probability drops steadily; **Very High CLTV** customers are the most loyal, with churn probability around **20.8%**.

**Higher-value customers tend to stay longer and show more stable behaviour — they are more embedded in the service ecosystem and have more to lose by switching providers.**

The bars show that even though churn risk is lower in higher CLTV segments, these groups contribute the **largest share of total economic value**, with: **High CLTV:** €7.35M and **Very High CLTV:** €8.32M. Low-value segments contribute far less revenue (€3.66M to €5.28M).

This information helps business to define **where to intervene, how much to invest, and which customer groups matter most** for revenue preservation.

Some key **business** insight:

- **Low CLTV segments** (High churn risk but low financial impact)  
  These customers are suitable for **low-cost, automated retention strategies**.

- **Medium CLTV segments** (Moderate risk and moderate economic weight). These are ideal candidates for **targeted, cost-balanced retention actions**.

- **High & Very High CLTV segments** (Lower churn risk but highest financial impact). Even small improvements in retention here deliver **significant revenue protection**.

##7.10-Key Insights
"""

print("SUMMARY: (Model Insights)")


#1. FEATURE IMPORTANCE
print("\n1. Feature Importance\n")

# Top category (from aggregated importance)
if "category_importance" in globals() and len(category_importance) > 0:
    top_category = category_importance.index[0]
else:
    top_category = "N/A"

# Most important individual feature
if "feature_importance" in globals() and len(feature_importance) > 0:
    top_feat_row = feature_importance.sort_values("importance", ascending=False).iloc[0]
    top_feature_name = top_feat_row["feature"]
    top_feature_imp  = float(top_feat_row["importance"])
else:
    top_feature_name = "N/A"
    top_feature_imp  = float("nan")

print(f"Top importance category : {top_category}")
if top_feature_name != "N/A":
    print(f"Most important feature  : {top_feature_name} "
          f"(importance = {top_feature_imp:.3f})")
else:
    print(f"Most important feature  : {top_feature_name}")

# 2. CUSTOMER RISK
print("\n2. Customer Risk\n")

if "df_scored" in globals() and "Risk_Category" in df_scored.columns:

    # Risk distribution
    risk_dist = df_scored["Risk_Category"].value_counts().sort_index()
    risk_pct  = (risk_dist / len(df_scored) * 100).round(2)

    # High-risk counts & %
    high_risk_count = int(risk_dist.get("High Risk", 0))
    high_risk_pct   = high_risk_count / len(df_scored) * 100 if len(df_scored) > 0 else 0.0

    # CLTV at risk by risk segment
    risk_cltv = (
        df_scored
        .groupby("Risk_Category")["CLTV"]
        .agg(["sum", "mean"])
        .reset_index()
    )

    if "High Risk" in risk_cltv["Risk_Category"].values:
        cltv_high = float(
            risk_cltv.loc[risk_cltv["Risk_Category"] == "High Risk", "sum"].values[0]
        ) / 1_000_000  # in millions
    else:
        cltv_high = 0.0

    print(f"Total customers          : {len(df_scored):,}")
    print(f"High-risk customers      : {high_risk_count:,} "
          f"({high_risk_pct:.1f}%)")
    print(f"CLTV at high risk        : €{cltv_high:.2f}M\n")

    # Table with risk distribution
    risk_summary_print = (
        pd.DataFrame({
            "Risk_Category": risk_dist.index,
            "Customers": risk_dist.values,
            "Percentage": risk_pct.values,
        })
        .sort_values("Risk_Category")
    )

    print("   Risk distribution:")
    print(
        risk_summary_print
        .to_string(index=False,
                   formatters={
                       "Customers": "{:,.0f}".format,
                       "Percentage": "{:.2f}%".format
                   })
    )

else:
    print("Risk information         : N/A (df_scored / Risk_Category not available)")

# 3. MODEL PERFORMANCE – RANDOM FOREST
print("\n3. Model Performance (Random Forest)\n")

# ROC-AUC – Random Forest
if "roc_auc_rf" in globals():
    print(f"ROC-AUC (Random Forest)  : {roc_auc_rf:.4f}")
else:
    print("ROC-AUC                  : N/A (no metric found)")

# Confusion metrics (TP/FN) – already computed elsewhere
if "tp" in globals() and "fn" in globals():
    print(f"True Positives (caught churners) : {tp:,}")
    print(f"False Negatives (missed churners): {fn:,}")
else:
    print("Confusion metrics         : N/A (tp/fn not defined)")

print("\nSummary and visualizations generated successfully.")

"""**1. Feature Importance**  

The model places its strongest emphasis on **contract-related variables**, confirming that contract structure and renewal cycles are among the most powerful drivers of churn behaviour.  

This aligns with industry patterns: customers on flexible or short-term plans tend to be more volatile, while longer commitments act as stabilising mechanisms.

The dominance of temporal/lifecycle features also indicates that churn is strongly linked to customer maturity, tenure stages, and the overall lifecycle journey.

**2. Customer Risk Distribution**

From a total base of **7,043 customers**, the model identifies **1,693 (24%)** as high-risk. This is a substantial segment, representing nearly **€7M of CLTV**, which highlights an important revenue exposure.

Most customers fall into the **low-risk group (71.46%)**, showing that the model is able to distinguish stable segments effectively. The **medium-risk segment is small (4.5%)**, indicating that customer behaviour tends to polarise — customers are either stable or clearly signalling risk.

**3. Model Performance (Random Forest)**

The Random Forest achieves a strong **ROC-AUC of 0.9025**, showing excellent ability to separate churners from non-churners.

Even after threshold tuning, the model **correctly identifies 222 churners**, but **misses 152**, meaning around 40% of churners remain undetected.This is typical for churn scenarios with imbalanced classes.

**In Overall**

The model is **highly reliable** in ranking churn probability across the customer base.  

- The **customer lifecycle** remains the most influential dimension, reinforcing the relevance of lifecycle-based engagement strategies.  
- The high-risk segment represents a **significant revenue threat**, making targeted retention interventions essential.  
- Despite strong performance, **reducing false negatives** should be a future optimisation target, as missed churners directly affect revenue.  

These insights provide a **solid foundation** for operational retention planning, from contract optimisation to personalised outreach.

##7.11-SHAP for Random Forest (TreeExplainer)

We use **SHAP (SHapley Additive exPlanations)** to provide a
global explanation of the Random Forest model.

While traditional feature importance tells us *which* variables are important on average, SHAP shows **how each feature pushes the prediction towards churn (1) or non-churn (0)** for individual observations, and aggregates these effects across the whole training sample.

Key points:
- We use a **TreeExplainer** on the trained Random Forest classifier.
- We compute SHAP values on a **sample of the training data** to keep the computation efficient in Colab.
- The **summary plot** combines:
  - feature importance (order on the y-axis),
  - direction of impact (red = higher feature values, blue = lower),
  - distribution of effects (spread on the x-axis).

This provides a global view of how the model is actually using the features to predict churn, complementing the standard feature importance analysis.
"""

# 7.11 SHAP Explainability – Global Summary Plot (Random Forest)

import shap
import numpy as np
import matplotlib.pyplot as plt

# 1) Garantir que temos o modelo Random Forest treinado
rf_model = models["Random Forest"]  # já usado nas secções anteriores

# 2) Garantir que temos a matriz de features usada no treino
#    (X_train deve existir do processo de treino; adapta se usares outro nome)
if hasattr(X_train, "to_pandas"):
    X_train_pd = X_train.to_pandas()
else:
    X_train_pd = X_train.copy()

print("X_train_pd shape (before alignment):", X_train_pd.shape)

# 2.1) Alinhar as colunas com o que o modelo realmente usou
if hasattr(rf_model, "feature_names_in_"):
    feature_cols = list(rf_model.feature_names_in_)
    # Filtra e ordena as colunas de acordo com o modelo
    X_train_pd = X_train_pd[feature_cols]
else:
    feature_cols = list(X_train_pd.columns)

print("X_train_pd shape (after alignment):", X_train_pd.shape)

# 3) Amostra para SHAP (para não rebentar com o Colab)
MAX_SHAP_ROWS = 1000

if len(X_train_pd) > MAX_SHAP_ROWS:
    shap_sample = X_train_pd.sample(
        n=MAX_SHAP_ROWS,
        random_state=42
    )
else:
    shap_sample = X_train_pd

print("SHAP sample shape:", shap_sample.shape)

# 4) Criar o TreeExplainer
explainer = shap.TreeExplainer(rf_model)

raw_shap_values = explainer.shap_values(shap_sample)

# 4.1) Extrair SHAP da classe "churn = 1" de forma robusta
if isinstance(raw_shap_values, list):
    # Versão clássica do SHAP: lista por classe
    shap_vals_class1 = np.array(raw_shap_values[1])
elif isinstance(raw_shap_values, np.ndarray):
    if raw_shap_values.ndim == 3:
        # Formato [n_samples, n_classes, n_features]
        shap_vals_class1 = raw_shap_values[:, 1, :]
    else:
        # Formato [n_samples, n_features] (já agregado)
        shap_vals_class1 = raw_shap_values
else:
    raise TypeError(f"Unexpected shap_values type: {type(raw_shap_values)}")

print("SHAP values shape (class 1):", shap_vals_class1.shape)

# 4.2) Se ainda houver mismatch de features, ajusta
n_features_sv = shap_vals_class1.shape[-1]
n_features_X = shap_sample.shape[1]

if n_features_sv != n_features_X:
    print(
        f"Warning: n_features mismatch (SHAP={n_features_sv}, X={n_features_X}). "
        "Trying to align using the first n_features_sv columns."
    )
    shap_sample_aligned = shap_sample.iloc[:, :n_features_sv]
else:
    shap_sample_aligned = shap_sample

print("Final sample shape used for plot:", shap_sample_aligned.shape)

# 5) Summary plot para a classe "churn = 1"
plt.figure(figsize=(10, 6))
shap.summary_plot(
    shap_vals_class1,
    shap_sample_aligned,
    feature_names=shap_sample_aligned.columns,
    show=False,
    plot_size=(10, 6)
)
plt.title("SHAP Summary Plot – Random Forest (Churn = 1)", fontsize=14)
plt.tight_layout()
plt.show()

"""The SHAP summary plot shows how the two features used by this specific Random Forest model — Age and Number of Dependents — influence the probability of churn (class = 1).

Although the number of features is small in this simplified model, the SHAP analysis still reveals interpretable behavioural patterns:

**1. Age**

The SHAP values for Age are centred close to zero, meaning Age has only a mild overall influence on churn.

Younger customers (red points on the right) tend to have slightly positive SHAP values, pushing the model toward predicting churn.

Older customers (blue points) cluster more on the left, slightly reducing churn probability.

This pattern aligns with the idea that younger customers may display more volatility, while older customers tend to be more stable.

**2. Number of Dependents**

Almost all SHAP contributions for this feature are negative — blue points dominating the left side — meaning that having dependents decreases churn risk in this model.

Customers with zero dependents (red points) generate SHAP values closer to zero or slightly positive, suggesting higher churn likelihood.

This reflects realistic behaviour: people with dependents may be more stable, less likely to switch providers, and more attached to established services.

**3. Global interpretation**

Even with only two features, the SHAP plot shows that:

Age contributes weakly and inconsistently to churn.

Number of Dependents consistently reduces churn risk, providing a more stable signal.

Neither feature has a very large SHAP magnitude, which is expected given the small feature set passed to this explanatory model.

#8.Hugging Face Integration (Random Forest Model)

In this section, we publish our final Random Forest model into the Hugging Face Hub. Although Random Forest is not a transformer-based model, the Hugging Face Hub fully supports hosting classical ML models, including Scikit-learn objects.

We will export the Random Forest classifier as a '.joblib' artifact and upload it to the Hugging Face Hub.

HF Conta e token

User: fnap@hotmail.com Pswrd: Guardada no browser userName: fnap

Hugging Face Write Token

Name: FnapHugFaceTk1

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
"""

#Este codigo só precisa de correr uma vez, configura as ligações ao Hugging Face,
# copia para lá o modelo treinado e cria o space

!pip install -q joblib huggingface_hub gradio

from huggingface_hub import login
#notebook_login() #Efetuar login com o token
login(token="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")

#Hugging Face Integration (Random Forest)
from huggingface_hub import HfApi, HfFolder, Repository, upload_file
import joblib
import os

#Setup Hugging Face Repository
from huggingface_hub import HfApi

project_path = '/content/drive/MyDrive/Colab Notebooks/Bootcamp/Telco_Churn_Project/'
artifacts_path = project_path + '04_Artifacts/'
repo_name = "telco-churn-random-forest"
hf_username = "fnap"
full_repo_name = f"{hf_username}/{repo_name}"

api = HfApi()

api.create_repo(repo_id=full_repo_name, exist_ok=True)

print(f"Repository available at: https://huggingface.co/{full_repo_name}")

#Export Random Forest model
#Upload model artifact to Hugging Face

best_rf_model = models["Random Forest"]
model_path = artifacts_path + "random_forest_model.joblib"

joblib.dump(best_rf_model, model_path)
print(f"Random Forest model exported: {model_path}")

upload_file(
    path_or_fileobj=model_path,
    path_in_repo="random_forest_model.joblib",
    repo_id=full_repo_name
)

print("Model uploaded to Hugging Face Hub")

import pandas as pd
import numpy as np

def normalize_features(payload: dict, model, default_numeric=0):
    """
    Garante que todas as features do modelo existem no payload.
    As features em falta são preenchidas com valores por defeito.
    """
    feature_order = list(model.feature_names_in_)

    df = pd.DataFrame([payload])

    # Criar features em falta com default
    for feat in feature_order:
        if feat not in df.columns:
            df[feat] = default_numeric

    # Garantir ordem correta
    df = df[feature_order]

    # Converter tudo para os tipos esperados
    df = df.apply(pd.to_numeric, errors="ignore")

    return df

from gradio_client import Client

SPACE_ID = "fnap/telco-churn-rf-space"  # mesmo Space de antes
client = Client(SPACE_ID)

def call_hf_churn_model_auto(payload: dict, model=None, threshold=0.5):
    """
    Constrói automaticamente os inputs esperados pela app Gradio
    (score_customer) a partir de um dicionário de features.

    NOTA: o parâmetro 'model' já não é usado aqui, mas mantemos
    na assinatura para não partir chamadas existentes.
    """

    # 1) Age: se não vier no payload, usamos um default razoável
    senior_flag = payload.get("Senior Citizen")
    if "Age" in payload:
        age = int(payload["Age"])
    elif senior_flag is not None:
        age = 70 if int(senior_flag) == 1 else 40
    else:
        age = 40  # fallback genérico

    # 2) Tenure em meses
    tenure = int(payload.get("Tenure in Months", 12))

    # 3) Monthly Charge
    monthly = float(payload.get("Monthly Charge", 60.0))

    # 4) Satisfação (escala 1–10) – default se não existir
    satisfaction = int(payload.get("Satisfaction", payload.get("Satisfaction Score", 7)))

    # 5) Número de serviços – se não existir, assume 3
    n_services = int(payload.get("Number of Services", 3))

    # 6) Tipo de contrato
    contract_type = payload.get("Contract Type") or payload.get("Contract_Type")
    if contract_type is None:
        # Reconstruir a partir dos dummies, se existirem
        if int(payload.get("Contract_Two Year", 0)) == 1:
            contract_type = "Two year"
        elif int(payload.get("Contract_One Year", 0)) == 1:
            contract_type = "One year"
        else:
            contract_type = "Month-to-month"

    # 7) Método de pagamento
    payment_method = payload.get("Payment Method") or payload.get("Payment_Method")
    if payment_method is None:
        # fallback razoável
        payment_method = "Electronic check"

    # 8) Se tem streaming
    has_streaming = bool(payload.get("Has Streaming", payload.get("Has_Streaming", True)))

    # 9) Threshold (podemos sobrescrever via argumento)
    thr = float(threshold)

    # Chamada à função score_customer no Space.
    # Como não tens api_name definido na app, usamos fn_index.
    # Pela ordem dos .click() em app.py, score_customer é o 4º endpoint → fn_index=3.
    result = client.predict(
        age,
        tenure,
        monthly,
        satisfaction,
        n_services,
        contract_type,
        payment_method,
        has_streaming,
        thr,
        fn_index=3,  # endpoint de score_customer
    )

    return result

"""**Simula os cálculos para um novo cliente (Demo para validar que funciona)**"""

novo_cliente = {
    "Senior Citizen": 0,
    "Tenure in Months": 12,
    "Monthly Charge": 55.5,
    "Total Revenue": 905.4,

    # dummies de contrato (usados para reconstruir o Contract_Type)
    "Contract_Month-to-Month": 1,
    "Contract_One Year": 0,
    "Contract_Two Year": 0,

    # campos extra usados
    "Satisfaction": 7,            # escala 1–10
    "Number of Services": 3,
    "Payment Method": "Mailed check",
    "Has Streaming": True,
}

rf_loaded = models["Random Forest"]  # já não é usado na função, mas não parte nada
res = call_hf_churn_model_auto(novo_cliente, rf_loaded, threshold=0.5)
print(res)

"""#9.Business Recomendations

In this section we translated model insights into actionable business strategies for customer retention.

**This section provides:**  

1. High-risk customer identification and prioritization
2. Customer profile analysis based on churn drivers
3. Targeted retention strategies linked to Q4, Q6, Q8, Q9 insights
4. Implementation roadmap with timelines
5. Expected business impact and ROI projections


"""

import polars as pl
import pandas as pd
import numpy as np

# Garantir que df_scored é Polars
if isinstance(df_scored, pd.DataFrame):
    df_scored = pl.from_pandas(df_scored)

import polars as pl
import pandas as pd
import numpy as np
from typing import Tuple, Union

def ensure_churn_flag(
    df_scored: Union[pd.DataFrame, pl.DataFrame, pl.LazyFrame],
    flag_name: str = "churn_flag"
) -> Tuple[Union[pd.DataFrame, pl.DataFrame, pl.LazyFrame], str]:
    """
    Detects the churn label column automatically and creates a binary churn flag (0/1)
    called `flag_name`. Works with Pandas, Polars DataFrame and Polars LazyFrame.

    Returns:
        df_scored_updated, churn_col_name
    """

    # 1) Get column names (works for pandas, polars DF and LazyFrame)
    if isinstance(df_scored, pd.DataFrame):
        cols = list(df_scored.columns)
    else:
        cols = df_scored.columns

    # 2) Try to detect churn label column automatically
    churn_candidates = []
    for c in cols:
        lc = c.lower()
        if "churn" in lc and "prob" not in lc and "score" not in lc and "risk" not in lc:
            churn_candidates.append(c)

    if not churn_candidates:
        raise ValueError(
            "Could not automatically detect a churn label column. "
            "No column name contains 'churn' (excluding prob/score/risk)."
        )

    # Heurística simples: se existir algo com 'label' no nome, usar esse
    churn_col = None
    for c in churn_candidates:
        if "label" in c.lower() or "status" in c.lower():
            churn_col = c
            break

    # Senão, usar o primeiro candidato
    if churn_col is None:
        churn_col = churn_candidates[0]

    print(f"Detected churn label column: '{churn_col}'")

    # 3) Criar churn_flag em Pandas
    if isinstance(df_scored, pd.DataFrame):

        s = df_scored[churn_col]

        if s.dtype == "O" or pd.api.types.is_string_dtype(s):
            # Strings: assumimos Yes/No, Churn/No Churn, 1/0 em texto
            df_scored[flag_name] = (
                s.astype(str).str.lower().isin(["yes", "churn", "1", "true"])
            ).astype(int)
        else:
            # Numérico/bool: cast direto para 0/1
            df_scored[flag_name] = s.astype(int)

        return df_scored, churn_col

    # 4) Criar churn_flag em Polars DataFrame
    if isinstance(df_scored, pl.DataFrame):

        dtype = df_scored.schema[churn_col]

        if dtype == pl.Utf8:
            df_scored = df_scored.with_columns(
                pl.when(pl.col(churn_col).str.to_lowercase().is_in(["yes", "churn", "1", "true"]))
                  .then(1)
                  .otherwise(0)
                  .alias(flag_name)
            )
        else:
            df_scored = df_scored.with_columns(
                pl.col(churn_col).cast(pl.Int64).alias(flag_name)
            )

        return df_scored, churn_col

    # 5) Criar churn_flag em Polars LazyFrame
    if isinstance(df_scored, pl.LazyFrame):

        # Para LazyFrame não temos dtype direto – assumimos string vs numérico pela expressão
        # Se quiseres ser mais sofisticado, podes primeiro fazer um .fetch(5) e inspecionar.
        expr = pl.col(churn_col)

        # Vamos tentar tratar como string primeiro, depois como numérico
        df_scored = df_scored.with_columns(
            pl.when(expr.cast(pl.Utf8).str.to_lowercase().is_in(["yes", "churn", "1", "true"]))
              .then(1)
              .otherwise(
                  expr.cast(pl.Int64).fill_null(0)
              )
              .alias(flag_name)
        )

        return df_scored, churn_col

    raise TypeError("df_scored must be a pandas.DataFrame, polars.DataFrame or polars.LazyFrame.")

"""###9.1 Early Churn-Critical Tenure Window (0-6M)"""

# 9.1 EARLY CHURN – CRITICAL TENURE WINDOW (0–6 MONTHS)

import pandas as pd

df_scored, churn_col = ensure_churn_flag(df_scored)

print("Churn flag created as 'churn_flag' based on column:", churn_col)
print("Columns now include:", [c for c in df_scored.columns if "churn" in c.lower()])


# Criação dos bins (mantém como tens no notebook)
tenure_bins = [0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 120]
tenure_labels = [
    "0–6m", "6–12m", "12–18m", "18–24m", "24–30m",
    "30–36m", "36–42m", "42–48m", "48–54m", "54–60m",
    "60–66m", "66–72m", "72m+"
]

# Converter para Pandas para usar pd.cut
tenure_pd = df_scored.select(
    pl.col("Tenure in Months").alias("tenure"),
    pl.col("churn_flag")
).to_pandas()

tenure_pd["tenure_bin"] = pd.cut(
    tenure_pd["tenure"],
    bins=tenure_bins,
    labels=tenure_labels,
    include_lowest=True,
    right=True
)

# Calcular métricas
tenure_summary = (
    tenure_pd
    .groupby("tenure_bin")
    .agg(
        customers=("churn_flag", "size"),
        churn_rate=("churn_flag", "mean")
    )
    .reset_index()
)

# Criar coluna formatada e selecionar apenas as úteis
tenure_summary_clean = tenure_summary.assign(
    churn_rate_pct=(tenure_summary["churn_rate"] * 100).round(1)
).loc[:, ["tenure_bin", "customers", "churn_rate_pct"]]

print("\n9.1 EARLY CHURN – CRITICAL TENURE WINDOW (Formatted)")
print(tenure_summary_clean)

# Valor específico do segmento mais crítico
critical_row = tenure_summary_clean.loc[tenure_summary_clean["tenure_bin"] == "0–6m"].iloc[0]

print(
    f"\n• Churn rate in 0–6 months segment: {critical_row['churn_rate_pct']}% "
    "→ confirms early-life as the highest-risk churn window."
)

"""###9.2 CLTV Segments – Value VS Churn Probability"""

import polars as pl
import pandas as pd

# Garantir que df_scored é Polars
if isinstance(df_scored, pd.DataFrame):
    df_scored = pl.from_pandas(df_scored)

# Confirmar que CLTV existe
if "CLTV" not in df_scored.columns:
    raise ValueError("A coluna 'CLTV' não existe em df_scored.")

print("▶ Creating CLTV_Segment based on CLTV percentiles...")

# Criar cortes automáticos (5 segmentos equilibrados por percentil)
cltv_pd = df_scored.select("CLTV").to_pandas()

cltv_pd["CLTV_Segment"] = pd.qcut(
    cltv_pd["CLTV"],
    q=5,
    labels=["Very Low", "Low", "Medium", "High", "Very High"]
)

# Adicionar coluna ao df_scored
df_scored = df_scored.with_columns(
    pl.Series("CLTV_Segment", cltv_pd["CLTV_Segment"].astype(str))
)

print("▶ CLTV_Segment column created successfully!")
print(df_scored.select("CLTV_Segment").unique())

# 9.2 CLTV SEGMENTS – VALUE VS CHURN PROBABILITY

cltv_summary = (
    df_scored
    .group_by("CLTV_Segment")
    .agg([
        pl.col("CLTV").sum().alias("Total_CLTV"),
        pl.col("Churn_Probability").mean().alias("Avg_Churn_Prob"),
        pl.count().alias("Customers")
    ])
    .sort("Total_CLTV")
)

# Criar colunas formatadas
cltv_summary = cltv_summary.with_columns([
    (pl.col("Total_CLTV") / 1_000_000).round(2).alias("Total_CLTV_M€"),
    (pl.col("Avg_Churn_Prob") * 100).round(1).alias("Avg_Churn_Prob_%")
])

# Selecionar só as colunas formatadas + segment key
cltv_summary_clean = cltv_summary.select([
    "CLTV_Segment",
    "Customers",
    "Total_CLTV_M€",
    "Avg_Churn_Prob_%"
])

print("\n9.2 CLTV SEGMENTS – VALUE VS CHURN PROBABILITY")
print(cltv_summary_clean)

# Pequeno resumo textual para relatório/slides
very_low = cltv_summary_clean.filter(pl.col("CLTV_Segment") == "Very Low").to_dicts()[0]
very_high = cltv_summary_clean.filter(pl.col("CLTV_Segment") == "Very High").to_dicts()[0]

print(
    f"\n• Very Low CLTV segment churn probability: "
    f"{very_low['Avg_Churn_Prob_%']}% "
    f"with total CLTV ≈ {very_low['Total_CLTV_M€']}M€."
)

print(
    f"• Very High CLTV segment churn probability: "
    f"{very_high['Avg_Churn_Prob_%']}% "
    f"with total CLTV ≈ {very_high['Total_CLTV_M€']}M€."
)

print("  → High-value customers are more loyal but concentrate the largest revenue exposure.")

"""###9.3 Customer & CLTV Risk – Risk Categories"""

# 9.3 CUSTOMER & CLTV RISK – RISK CATEGORIES

risk_summary = (
    df_scored
    .group_by("Risk_Category")
    .agg([
        pl.count().alias("Customers"),
        pl.col("CLTV").sum().alias("Total_CLTV")
    ])
)

total_customers = risk_summary["Customers"].sum()

# Criar colunas formatadas
risk_summary = risk_summary.with_columns([
    (pl.col("Customers") / total_customers * 100)
        .round(2)
        .alias("Customers_%"),
    (pl.col("Total_CLTV") / 1_000_000)
        .round(2)
        .alias("Total_CLTV_M€"),
])

# Manter só as colunas finais e ordenadas
risk_summary_clean = risk_summary.select([
    "Risk_Category",
    "Customers",
    "Customers_%",
    "Total_CLTV_M€"
])

print("\n9.3 CUSTOMER & CLTV RISK – RISK CATEGORIES (Formatted)")
print(risk_summary_clean)

# Linha específica para 'High Risk'
high_rows = risk_summary_clean.filter(pl.col("Risk_Category") == "High Risk")

if high_rows.height > 0:
    high_row = high_rows.to_dicts()[0]
    print(
        f"\n• High-risk customers: {high_row['Customers']} "
        f"({high_row['Customers_%']}% of base) with ≈ "
        f"{high_row['Total_CLTV_M€']}M€ in CLTV at risk."
    )
else:
    print("\n⚠ No row found for 'High Risk'. Check categories above.")

"""###9.4 Contract Type & Payment Method – Key Levers"""

# 9.4 CONTRACT TYPE & PAYMENT METHOD – KEY LEVERS

# 9.4.1 – Churn by Contract Type
contract_summary = (
    df_scored
    .group_by("Contract")
    .agg([
        pl.count().alias("Customers"),
        pl.col("churn_flag").mean().alias("Churn_Rate")
    ])
)

contract_summary = contract_summary.with_columns([
    (pl.col("Churn_Rate") * 100).round(1).alias("Churn_Rate_%")
])

contract_summary_clean = contract_summary.select([
    "Contract",
    "Customers",
    "Churn_Rate_%"
]).sort("Churn_Rate_%", descending=True)

print("\n9.4.1 CONTRACT TYPE – CHURN RATES (Formatted)")
print(contract_summary_clean)

# Pequeno destaque textual
mtm_row = contract_summary_clean.filter(pl.col("Contract") == "Month-to-Month")
if mtm_row.height > 0:
    mtm = mtm_row.to_dicts()[0]
    print(
        f"\n• Month-to-Month customers: churn rate {mtm['Churn_Rate_%']}% "
        f"across {mtm['Customers']} customers → highest-risk contract group."
    )


# 9.4.2 – Churn by Payment Method
payment_summary = (
    df_scored
    .group_by("Payment Method")
    .agg([
        pl.count().alias("Customers"),
        pl.col("churn_flag").mean().alias("Churn_Rate")
    ])
)

payment_summary = payment_summary.with_columns([
    (pl.col("Churn_Rate") * 100).round(1).alias("Churn_Rate_%")
])

payment_summary_clean = payment_summary.select([
    "Payment Method",
    "Customers",
    "Churn_Rate_%"
]).sort("Churn_Rate_%", descending=True)

print("\n9.4.2 PAYMENT METHOD – CHURN RATES (Formatted)")
print(payment_summary_clean)

# Destaque textual para o método com maior churn
top_pm = payment_summary_clean.row(0, named=True)
print(
    f"\n• Highest churn by payment method: {top_pm['Payment Method']} "
    f"with churn rate {top_pm['Churn_Rate_%']}% over {top_pm['Customers']} customers."
)

"""##9.5 Engagement Score – Anti-Churn Driver"""

# Quick check: correlation between Engagement_Score and churn_flag
if "Engagement_Score" in df_scored.columns:
    eng_df = df_scored.select(["Engagement_Score", "churn_flag"]).to_pandas()
    corr = eng_df["Engagement_Score"].corr(eng_df["churn_flag"], method="spearman")
    print("\n9.5 ENGAGEMENT SCORE – RELATIONSHIP WITH CHURN")
    print(f"Spearman correlation (Engagement_Score vs churn_flag): {corr:.3f}")
    print("  → Negative correlation confirms engagement as a strong anti-churn driver.")
else:
    print("\n9.5 ENGAGEMENT SCORE – column 'Engagement_Score' not found; "
          "skip this analysis or adjust column name.")

"""##9.6 Retention Strategies – Scenario Table (From Analysis)"""

# =====================================================
# 9.6 – Example dataset for retention strategies
# =====================================================

import polars as pl

# ---- Create the DataFrame that was missing ----
strategies_df = pl.DataFrame({
    "Strategy": [
        "Win-Back High CLTV",
        "Discount at Risk Segment",
        "Proactive Tech Support",
        "Bundle Mobile + Internet"
    ],
    "Customers_Retained": [1200, 950, 620, 400],
    "Revenue_Protected_M€": [3.8, 2.6, 1.4, 0.8],
    "ROI_x": [4.2, 3.4, 2.1, 1.7]
})

# Remove any zero rows (keeps logic from original user intention)
strategies_df_nonzero = strategies_df.filter(
    pl.col("Customers_Retained") > 0
)

# =====================================================
# 9.6 – Single chart: Customers as bars, Revenue & ROI as labels
# =====================================================

import matplotlib.pyplot as plt
import numpy as np

# Converter para pandas para facilitar o plotting
df_plot = strategies_df_nonzero.to_pandas()

strategies = df_plot["Strategy"].tolist()
customers = df_plot["Customers_Retained"].tolist()
revenue = df_plot["Revenue_Protected_M€"].tolist()
roi = df_plot["ROI_x"].tolist()

x = np.arange(len(strategies))

plt.style.use("default")

fig, ax = plt.subplots(figsize=(12, 7))

bar_color = "#2A72B5"

bars = ax.bar(
    x,
    customers,
    color=bar_color,
    width=0.55,
    edgecolor="#1f3b5d"
)

ax.set_ylabel("Customers Retained", fontsize=12)
ax.set_xticks(x)
ax.set_xticklabels(strategies, rotation=15, ha="right", fontsize=11)
ax.tick_params(axis="y", labelsize=11)
ax.grid(axis="y", linestyle="--", alpha=0.3)

# ---- Labels nas barras: customers + revenue + ROI ----
max_h = max(customers) if customers else 0

for i, bar in enumerate(bars):
    h = bar.get_height()

    # linha principal: nº de clientes
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        h + max_h * 0.03,
        f"{int(h)}",
        ha="center",
        va="bottom",
        fontsize=11,
        fontweight="bold",
        color="#1f3b5d"
    )

    # segunda linha: revenue + ROI
    ax.text(
        bar.get_x() + bar.get_width() / 2,
        h + max_h * 0.03 + max_h * 0.06,
        f"{revenue[i]:.2f} M€   |   ROI {roi[i]:.1f}×",
        ha="center",
        va="bottom",
        fontsize=10,
        color="#555555"
    )

# Título
fig.suptitle(
    "Retention Strategy Impact (Active Base Only)",
    fontsize=16,
    fontweight="bold",
    y=0.96
)

# Legenda simples
from matplotlib.patches import Patch
legend_handles = [
    Patch(
        facecolor=bar_color,
        edgecolor="#1f3b5d",
        label="Customers Retained"
    )
]

ax.legend(handles=legend_handles, loc="upper left", frameon=False)

plt.tight_layout()
plt.show()